{"meta":{"title":"Giraffe's Home","subtitle":"A Stupid Giraffe","description":"Add more ~ing into your life","author":"Mengying Ye","url":"http://yemengying.com"},"pages":[{"title":"关于我","date":"2016-04-02T05:20:37.000Z","updated":"2016-04-08T00:36:44.000Z","comments":true,"path":"about/index.html","permalink":"http://yemengying.com/about/index.html","excerpt":"","keywords":null,"text":"普通程序员，目前在某家外卖订餐平台从事Java开发，对python和搜索也有所了解。生活大爆炸和Running man脑残粉，因为很喜欢李光洙(外号长颈鹿)，所以博客取名为Giraffe’s Home，用来记录学习思考中的一些收获，也许会有错误，也许并不完美，但这不就是成长的过程么。没什么宏伟的目标，只希望每天都能有所收获，add more ing into my life。😜😜😜 有机会为值得的事情而努力是人生最好的犒赏~~","raw":null,"content":null},{"title":"Categories","date":"2016-03-19T01:28:47.000Z","updated":"2016-02-02T05:59:56.000Z","comments":true,"path":"categories/index.html","permalink":"http://yemengying.com/categories/index.html","excerpt":"","keywords":null,"text":"","raw":null,"content":null},{"title":"友情链接","date":"2016-04-18T13:51:56.000Z","updated":"2016-04-18T13:51:56.000Z","comments":true,"path":"friends/index.html","permalink":"http://yemengying.com/friends/index.html","excerpt":"","keywords":null,"text":"三”观”茅庐（一个做过后端，前端，目前在做移动端的程序猴的博客）","raw":null,"content":null},{"title":"留言","date":"2016-04-23T00:33:06.000Z","updated":"2016-04-23T00:33:06.000Z","comments":true,"path":"message/index.html","permalink":"http://yemengying.com/message/index.html","excerpt":"","keywords":null,"text":"欢迎大家留言~ 一起交流，学习，努力，成长吧 🎉🎉🎉~~","raw":null,"content":null},{"title":"RESULT","date":"2016-03-19T01:28:47.000Z","updated":"2016-01-18T05:59:08.000Z","comments":false,"path":"search/index.html","permalink":"http://yemengying.com/search/index.html","excerpt":"","keywords":null,"text":"","raw":null,"content":null},{"title":"Tags","date":"2016-03-19T01:28:47.000Z","updated":"2016-02-02T05:59:56.000Z","comments":true,"path":"tags/index.html","permalink":"http://yemengying.com/tags/index.html","excerpt":"","keywords":null,"text":"","raw":null,"content":null}],"posts":[{"title":"【译】利用Redis起飞吧","slug":"take-advantage-of-Redis","date":"2016-04-02T02:56:03.000Z","updated":"2016-04-22T13:38:08.000Z","comments":true,"path":"2016/04/02/take-advantage-of-Redis/","link":"","permalink":"http://yemengying.com/2016/04/02/take-advantage-of-Redis/","excerpt":"一直以来对Redis的使用都很是简单粗暴，不得精髓，趁假期好好补补。翻译一篇Redis之父Antirez的博客，文章中讲述了几个利用Redis解决实际问题的例子。并非逐字逐句的翻译，有些不太懂的地方就任性的跳过了😋，翻译这篇博客只做加深印象之用，建议大家还是出门左转看原文吧。。。。。。 原文地址：http://oldblog.antirez.com/post/take-advantage-of-redis-adding-it-to-your-stack.html","keywords":null,"text":"一直以来对Redis的使用都很是简单粗暴，不得精髓，趁假期好好补补。翻译一篇Redis之父Antirez的博客，文章中讲述了几个利用Redis解决实际问题的例子。并非逐字逐句的翻译，有些不太懂的地方就任性的跳过了😋，翻译这篇博客只做加深印象之用，建议大家还是出门左转看原文吧。。。。。。 原文地址：http://oldblog.antirez.com/post/take-advantage-of-redis-adding-it-to-your-stack.html 写在前面 Redis在很多方面不同于MySql等数据库：比如，Redis使用内存做主要的存储，使用磁盘实现数据持久化；数据模型不同；Redis是单线程的等等。但我认为最大的不同是如果开发者想要使用Redis，无需切换到Redis。可以在不把Redis作为数据库的前提下，利用Redis实现一些以前不好实现的功能或者优化遗留的问题。 完全切换到Redis当然也是可行的，许多开发者在想使用Redis的一些特性时，会将Redis当做主数据库，但将一个已经在生产环境中运行的项目切换到Redis显然是个大工程。而且有一些应用并不适合将Redis作为数据库：比如Redis的数据集不能比可用内存大，所以对于大数据量的应用，Redis可能不是一个好的选择。下面会介绍一些在已有项目中加入Redis的例子，会向大家展示如何在不把Redis当做主要数据库的情况下利用Redis的某些特性解决问题。 在主页展示最新的评论列表我敢打赌，如果每次都通过下面的查询语句获取最新评论，那么网站性能会很差。1SELECT * FROM foo WHERE ... ORDER BY time DESC LIMIT 10 展现最新添加的某些东西在网站应用中十分常见，下面看看如何利用Redis优化这类问题。假设网站想要展示最新的20条评论，并且还有个“展示全部评论”的链接，通过这个链接可以通过分页的形式查看历史评论记录。我们还假设每条评论都存储在数据库中，并且有一个自增的Id。我们可以使用一个很简单的Redis同时解决展现最新评论和分页展现历史评论的问题。 每当创建一条新的评论，将评论的Id插入到Redis的一个列表中:LPUSH latest.comments Redis支持将列表修剪到指定长度。所以我们可以通过LTRIM latest.comments 0 5000.操作维持列表中始终存储5000个最新的评论Id. 每次想要获取指定范围内的评论时，可以使用下面的函数（伪代码）. 1234567FUNCTION get_latest_comments(start,num_items): id_list = redis.lrange(\"latest.comments\",start,start+num_items-1) IF id_list.length &lt; num_items id_list = SQL_DB(\"SELECT ... ORDER BY time LIMIT ...\") END RETURN id_listEND 这段代码的功能很简单。在Redis中维护一个“动态缓存”，经常更新,存储最新评论的Id,缓存中限制最多只存5000个Id。在系统第一次启动时,缓存列表中的Id个数为0。所以我们上面实现的方法会在先访问Redis，如果参数(start/count)的超过了列表范围，再去访问数据库。我们无需刷新缓存，并且只会在用户想要查看最新5000条评论之外的评论时才会访问数据库。也就是说展示最新评论的主页，和查看历史评论前几页都无需访问数据库。 删除和过滤在遇到评论被删除时，我们可以使用LREM命令来删除Redis列表中缓存的评论Id。如果删除评论的情况不常见，也可以在展示指定评论时跳过它，因为我们在根据评论Id去数据库查询评论具体内容时，数据库会告诉我们某条评论已经不存在了。 选手积分榜及相关问题另一个比较常见的，用数据库实现性能较差的需求是按分数排序，展现列表，并且实时更新，一个常见的例子就是在线游戏中的选手积分榜。在在线游戏中，需要接受高频率的来自不同用户的分数更新，通过这些分数实现以下需求： 在积分榜中展现分数最高的100位选手 展现用户的当前排名 这些操作用Redis的有序集合来实现是很简单的，哪怕你的系统每分钟要更新上百万的分数。每当接受到一个用户的新分数时，我们对Redis做如下的操作： 1ZADD leaderboard &lt;score&gt; &lt;username&gt; ps:也可以使用userId，而不是用户名, 看开发者的个人喜好。接下来，我们可以很简单的通过下面的操作获得分数排名前100的用户 1ZREVRANGE leaderboard 0 99 也可以通过 1ZRANK leaderboard &lt;username&gt; 来获取用户的当前排名。除此之外，我们还可以获得排名靠近当前用户的用户，以及等等等等。。。。。 按照用户投票和时间排序下面谈谈选手积分榜问题的一个变种问题。在诸如Reddit和Hacker News这类的网站中，新闻是按照类似下面公式计算得出的分数来排序的。1score = points / time^alpha 也就是说用户的投票会在一定很小程度上提升新闻的排名，而时间流逝则会使新闻的排名呈指数级下降。实际的算法会比我们的例子更复杂，但解决的方式是一样的。首先假设只有最新发布的1000条新闻才有资格出现在首页上，所以我们只关注最新发布的1000条新闻，忽略太老的新闻，大致解决方法如下： 每当新发布一条新闻，将其Id加入到Redis的列表中，通过LPUSH+LTRIM将列表维持到只保存最新发布的1000条新闻的Id。 通过一个定时任务获取Redis中Id列表，并且不断的计算列表中新闻的分数。将计算结果通过ZADD操作存储到一个有序集合中，同时将旧的新闻从有序列表中清除。 主要思想就是，有序集合中存储着1000条最新新闻，并按分数排序。分数的排序是通过后台程序完成的，与浏览网站的用户数无关。 将元素过期我们还可以利用有序集合实现将超过指定时间的元素在数据库中删除或置为过期。具体做法如下： 每当数据库中新加入一个元素时，同时将其添加到有序集合中，分数是当前时间加上指定的存活时间 让一个后台任务查询有序集合，利用ZRANGE …WITHSCORES获取元素，如果元素对应的分数小于当前时间，说明元素已过期，在数据库中删除对应记录。 计数器Redis可以用来实现计数器,使用INCRBY操作即可。相信很多人都曾想过在数据库中添加一张计数器表，用来为用户展现一些统计信息，但又考虑到需要对这张表进行大量的写操作而放弃，本宝宝曾经无数次遇到过这个问题。现在，我们可以通过Redis来解决这个问题。通过Redis我们可以为计数器原子性的增加计数,也可以使用GETSET命令重置计数器或者为计数器设置过期时间。比如我们可以按照如下做法实现计数一个用户指定时间内的页面访问量，如果超过了指定值，比如20，就弹出一个提示。 12INCR user:&lt;id&gt;EXPIRE user:&lt;id&gt; 60 统计指定时间内不同的用户另一个用数据库实现比较困难，但是用Redis却很简单的功能就是统计指定时间内访问某资源的用户数。比如我想知道访问指定页面的用户数(相同用户访问多次只计算一次)，我只需要在新增一个页面浏览(PV)时,执行下面的操作：1SADD page:day1:&lt;page_id&gt; &lt;user_id&gt; 想获得某页面的用户访问数，只需执行SCARD page:day1:即可。 实时分析我们已经看过了几个利用Redis如何实现一些利用数据库不好实现的功能，如果深入学习Redis的命令集，活用Redis中的数据结构，我们可以很容易的实现实时统计的功能，用来增强反垃圾邮件系统，或者通过分析得到的一些数据来提高网站的质量。 发布/订阅Redis中实现了一个高性能的发布/订阅系统，易于使用，稳定，性能高，并且支持模式匹配。详细的信息可以阅读Redis官方文档 队列大家可能已经注意到了，通过Redis对列表插入元素和弹出元素的命令，很适合用来实现一个队列。但Redis能做的远远不止这些，比如Redis弹出列表元素时还有提供BLPOP命令，可以在列表为空时，将连接阻塞。除此之外利用有序集合也可以很容易的实现一个优先队列。Redis在队列方面还有很多用法(比如RPOPLPUSH,Resque)，大家可以慢慢发掘。 缓存关于这一节其实就够再写一篇博客了。简单来说，Redis可以作为memcached的替代品，使我们的缓存既可以存储数据又易于更新。 快在Redis的帮助下起飞吧快使用Redis来增强用户体验，降低系统复杂度，加快请求响应吧~~，无需全部切换到Redis，可仅仅利用Redis实现用数据库不好实现或性能不高的新功能。 分享个觉得还不错的视频，拖延症患者可以看看，不过估计也没什么卵用，该拖还得拖，哈哈哈哈哈哈~~~","raw":null,"content":null,"categories":[{"name":"redis","slug":"redis","permalink":"http://yemengying.com/categories/redis/"}],"tags":[{"name":"翻译","slug":"翻译","permalink":"http://yemengying.com/tags/翻译/"},{"name":"redis","slug":"redis","permalink":"http://yemengying.com/tags/redis/"}]},{"title":"[Elasticsearch配置项(二)]Node,Threadpool模块配置","slug":"elasticsearch-settings2","date":"2016-03-21T13:32:41.000Z","updated":"2016-04-08T00:32:07.000Z","comments":true,"path":"2016/03/21/elasticsearch-settings2/","link":"","permalink":"http://yemengying.com/2016/03/21/elasticsearch-settings2/","excerpt":"接上文。。。。。。按照官方文档(版本2.2)和一些参考资料整理一下elasticsearch的可配置项。先整理了Node，ThreadPool两个模块的可配置项，其他模块(比如Cluster)会在之后慢慢整理的。本文只包含两个模块可用配置项的含义及用法，并不涉及应该如何优化，这是为什么呢？因为俺也不会。。。。。(欢迎指正错误，康桑阿米达) 相关博客：elasticsearch 配置项(一) wuli光洙镇楼~~","keywords":null,"text":"接上文。。。。。。按照官方文档(版本2.2)和一些参考资料整理一下elasticsearch的可配置项。先整理了Node，ThreadPool两个模块的可配置项，其他模块(比如Cluster)会在之后慢慢整理的。本文只包含两个模块可用配置项的含义及用法，并不涉及应该如何优化，这是为什么呢？因为俺也不会。。。。。(欢迎指正错误，康桑阿米达) 相关博客：elasticsearch 配置项(一) wuli光洙镇楼~~ 参考文档（万分感谢） http://www.opscoder.info/es_threadpool.html http://www.voidcn.com/blog/BrotherDong90/article/p-3851633.html Node(节点)每当启动一个Es实例，就是启动了一个节点。多个连接在一起的节点组成的集合就是集群。默认情况下，每个节点都可以通过HTTP和Transport通信。每个节点都知道集群中的其他节点，可以将客户端的请求转发到合适的节点。除此之外，每个节点还有着以下一种或多种具体角色。 Master-eligible node (候选主节点) 当一个节点的node.master被设置为true(默认为true)时，该节点就有资格被选为master节点，控制集群。 Data node (数据节点) 配置项node.data设置为true的节点称为数据节点。数据节点存储数据并且处理和数据相关的一些操作，比如CRUD，查找和聚合等。 Client node (客户端节点) 当一个节点的node.master和node.data均被设置为false时，它既不能存储数据也不能作为一个主节点。它被看做一个“路由器”，负责将集群层面的请求转发到主节点，将数据相关的请求转发到数据节点。 Tribe node (部落节点) 部落节点是一种特殊类型的客户端节点，可通过tribe.*配置项配置。部落节点可以连接多个集群，并且可以跨集群执行查找和其他操作。 默认情况下，每个节点即是主节点也是数据节点。但是当集群扩大后，更好的做法是将主节点和数据节点独立开。 Coordinating node(协调节点)：一些请求可能会涉及到多个数据节点，比如搜索或批量索引。搜索请求一般分为两个阶段，由接受客户端请求的节点做协调，称为协调节点。在搜索的第一阶段协调节点会将请求转发到数据节点，每个节点在本地执行请求，并将结果返给协调节点。在第二阶段，协调节点会将各个结果汇总在一起。这意味着负责接受请求的客户端节点(也就是协调节点)需要用足够的内存和CPU来处理查询结果的汇总。 Master-eligible node(候选主节点)主节点主要负责创建索引，删除索引，追踪集群中的节点，分配分片等，所以有一个稳定的主节点对于集群来说非常重要，非常重要，非常重要（说三遍，哈哈哈）。集群中任何有资格成为主节点的节点都可能被选为主节点。由于索引和搜索会对节点资源造成压力，在集群比较大时，最好将主节点和数据节点的角色区分，即不要让主节点同时也是数据节点。通过下面的配置可以设置一个专门的主节点(只是主节点不是数据节点)。12node.master: truenode.data: false 通过minimum_master_nodes来避免脑裂现象 discovery.zen.minimum_master_nodes配置项说明形成集群时，集群中有资格成为主节点的节点数最少是多少，默认为1.脑裂现象：假设集群中有两个有资格成为主节点的候选主节点，discovery.zen.minimum_master_nodes配置默认为1。当由于网络问题中断了两个节点间的通信，这时两个节点都只会发现一个有资格成为主节点的节点（自己本身）， 根据配置(minimum_master_nodes = 1),符合组成一个集群的条件，所以每个节点都会成为新的master节点，从而导致形成了两个集群，也就是脑裂。直到其中一个节点重启，才会重新形成集群，并且写入重启节点的数据会丢失。假设集群中有三个有资格成为主节点的候选主节点，而这时minimum_master_nodes设置为2，如果一个节点与其他两个失去了通信，被独立的节点会发现不满足设置的条件(有两个候选主节点)，所以不会选举自己为主节点。而剩下两个节点会选举出一个新的主节点，确保正常运行。 discovery.zen.minimum_master_nodes最好设置为(候选主节点数/2) + 1, 举个例子，当有三个候选主节点时，该配置项的值为(3/2)+1=2。也可以通过下面的API动态的更新这个值： 123456PUT _cluster/settings&#123; \"transient\": &#123; \"discovery.zen.minimum_master_nodes\": 2 &#125;&#125; Data node(数据节点)数据节点包含着索引文档的分片，负责处理和数据相关的操作，比如CRUD，搜索和聚合。这些操作会涉及到IO,内存和CPU，所以要注意监控这些资源，添加更多的数据节点以防负载过重。通过下面的配置可以设置一个专门的数据节点(只是数据节点不是主节点)。12node.master: falsenode.data: true Client node(客户端节点)客户端节点主要负责路由请求，汇总搜索结果等，本质上来看，客户端节点更像一个负载均衡器。 注意：集群中添加过多的客户端节点会增加整个集群的负担。所以不要过大夸大客户端节点的好处，数据节点也可以像客户端节点一样服务。 通过下面的配置可以设置一个专门的客户端节点(不是数据节点也不是主节点)。 12node.master: falsenode.data: false 设置节点的数据路径path.data每个数据节点和主节点都需要在文件中存储一些关于分片，索引和集群的元数据。elasticsearch.yml文件中的path.data可以配置文件的绝对路径或相对路径，默认值是$ES_HOME/data，也可以通过命令配置。 1./bin/elasticsearch --path.data /var/elasticsearch/data node.max_local_storage-nodes上面的设置可以被不同的节点共享（在生产环境下建议一个服务器只运行一个节点）。为了避免多个节点共享同一个路径，可以在elasticsearch.yml中添加如下配置。1node.max_local_storage_nodes: 1 注意，不要将不同类型节点的信息存储到同一个目录下，可能会造称数据丢失。 Thread Pool(线程池)为了提升线程内存消耗的管理，每个Es节点都有多个线程池。 线程池类型下面介绍一下线程池的三种类型和各自的一些参数：cached: cached类型的线程池没有限制大小，当有pending的请求时就会创建一个线程。这类线程池可以防止请求阻塞或被拒绝。未使用的线程会在过期(默认5分钟)之后消亡。cache类型专门为generic线程池保留的。 keep_alive参数定义了未使用的线程的存活时间。 123threadpool: generic: keep_alive: 2m fixed: fixed类型的线程池持有固定个数的线程处理请求队列。size参数用来控制线程的个数，默认为cpu核心数的5倍。queue_size参数用来控制请求队列的大小。默认值为-1，意味着无上限。如果请求队列已满，那么接下来到来的请求会被终止。 1234threadpool: index: size: 30 queue_size: 1000 scaling: scaling线程池中线程数可动态变化。线程数在1和size参数值的中间。 keep_alive参数定义了未使用的线程的存活时间。 1234threadpool: warmer: size: 8 keep_alive: 2m Es中重要的线程池以下是Es中几个比较重要的线程池及他们的类型: 线程池 作用 generic 负责一些诸如发现节点之类的通用操作。该线程池类型为cache。 index 负责索引数据/删除数据操作，类型为fixed，默认线程数为available processors,队列大小为200。 search 负责统计/搜索操作，类型为fixed,默认线程数为int((available_processors * 3) / 2) + 1,队列大小为1000。 suggest 负责获取提示操作，类型为fixed,默认线程数为available processors,队列大小为1000。 get 负责get操作，类型为fixed,默认线程数为available processors,队列大小为1000。 bulk 负责批量操作，类型为fixed,默认线程数为available processors,队列大小为50。 percolate 负责过滤操作，类型为fixed,默认线程数为available processors,队列大小为1000。 snapshot 负责快照/恢复操作，类型为scaling,默认线程数为min(5, (available processors)/2),默认未使用线程的存活时间为5m。 warmer 负责warm-up操作，类型为scaling,默认线程数为min(5, (available processors)/2),默认未使用线程的存活时间为5m。 refresh 负责更新操作，类型为scaling,默认线程数为min(10, (available processors)/2),默认未使用线程的存活时间为5m。 listener 负责java client的执行，类型为scaling,默认线程数为min(10, (available processors)/2),默认未使用线程的存活时间为5m。 处理器设置Es可以自动检测处理器的数量，线程池的配置也会基于这个值。可能存在检测失败的情况，这是可以通过processors配置显式设置这个值。 注意以上这些配置如果不是很了解，还是不要轻易改动，使用默认配置即可。 看累了吧，分享个觉得还不错的TED视频~~","raw":null,"content":null,"categories":[{"name":"elasticsearch","slug":"elasticsearch","permalink":"http://yemengying.com/categories/elasticsearch/"}],"tags":[{"name":"elasticsearch","slug":"elasticsearch","permalink":"http://yemengying.com/tags/elasticsearch/"}]},{"title":"[Elasticsearch配置项(一)]Local gateway,HTTP,Indices,Network Settings模块配置","slug":"Elasticsearch配置项-Local-gateway-HTTP-Indices-Network-Settings模块配置","date":"2016-03-18T09:48:10.000Z","updated":"2016-04-22T13:44:45.000Z","comments":true,"path":"2016/03/18/Elasticsearch配置项-Local-gateway-HTTP-Indices-Network-Settings模块配置/","link":"","permalink":"http://yemengying.com/2016/03/18/Elasticsearch配置项-Local-gateway-HTTP-Indices-Network-Settings模块配置/","excerpt":"近两周线上的搜索接口间隔性莫名其妙的出现莫名其妙的异常，比如神马NoAvailableThread，NoAvailableWorker之类的。可能是由于部门中没有很懂elasticsearch的人，只能摸着石头过河，所以一直使用elasticsearch的默认配置并没有对其线程池和内存分配进行优化造成的。所以按照官方文档(版本2.2)和一些参考资料整理一下elasticsearch的可配置项，看看可不可以优化一下。先整理了Local gateway,HTTP,Indices,Network Settings四个模块的可配置项，其他模块(比如Cluster)会在之后慢慢整理的。本文只包含四个模块可用配置项的含义及用法，并不涉及应该如何优化，这是为什么呢？因为俺也不会。。。。。(欢迎指正错误，康桑阿米达) 相关博客：elasticsearch 配置项(二)","keywords":null,"text":"近两周线上的搜索接口间隔性莫名其妙的出现莫名其妙的异常，比如神马NoAvailableThread，NoAvailableWorker之类的。可能是由于部门中没有很懂elasticsearch的人，只能摸着石头过河，所以一直使用elasticsearch的默认配置并没有对其线程池和内存分配进行优化造成的。所以按照官方文档(版本2.2)和一些参考资料整理一下elasticsearch的可配置项，看看可不可以优化一下。先整理了Local gateway,HTTP,Indices,Network Settings四个模块的可配置项，其他模块(比如Cluster)会在之后慢慢整理的。本文只包含四个模块可用配置项的含义及用法，并不涉及应该如何优化，这是为什么呢？因为俺也不会。。。。。(欢迎指正错误，康桑阿米达) 相关博客：elasticsearch 配置项(二) 参考资料(万分感谢)： http://donlianli.iteye.com/blog/2115979 http://aoyouzi.iteye.com/blog/2164820 http://blog.csdn.net/jingkyks/article/details/41081261 http://m.oschina.net/blog/387512 http://my.oschina.net/secisland/blog/618702?fromerr=ZGR1hlby#OSC_h4_5 https://github.com/chenryn/ELKstack-guide-cn/blob/master/elasticsearch/performance/cache.md Local gateway模块官网对应链接：Local gateway该模块用于存储集群信息和分片数据，以便整个集群重启后可以恢复。以下的一些静态配置，需要在集群的每一个节点上设置，用来控制节点需要等待多长时间之后再尝试恢复存储在本地的数据。 配置项 含义 gateway.expected_nodes 期望的集群中节点的数量，当集群中的节点数达到设定值时立即开始启动恢复本地数据的进程(会忽略recover_after_time配置)，默认为0 gateway.expected_master_nodes 期望的集群中master节点的数量，当集群中的节点数达到设定值时立即开始启动恢复本地数据的进程(会忽略recover_after_time配置)，默认为0 gateway.expected_data_nodes 期望的集群中master节点的数量，当集群中的节点数达到设定值时立即开始启动恢复本地数据的进程(会忽略recover_after_time配置)，默认为0 gateway.recover_after_time 当没有达到期望的节点数时，恢复进程会在等待配置时间之后尝试启动。当期望的节点数设置为1时，等待时间默认为5m 一旦到达了recover_after_time设置的时间，还要满足以下的配置条件，恢复进程才会启动。 配置项 含义 gateway.recover_after_nodes 需要多少个节点加入集群 gateway.recover_after_master_nodes 需要多少个master节点加入集群 gateway.recover_after_data_nodes 需要多少个data节点加入集群 注意：这些配置只有在整个集群重启时才会有用。 HTTP模块官网对应链接：HTTPHTTP模块用来通过HTTP暴露Es的API。因为HTTP机制是完全异步的，这意味着等待响应时不会阻塞线程。使用异步的通信可以解决C10k的问题。如果可以，可考虑使用HTTP keep alive来连接以便提升性能。并且不要在客户端使用HTTP chunking。 配置下面表中是关于HTTP模块的一些配置。需要注意的是，它们都不能动态更新，必须配置在elasticsearch.yml文件中。 配置项 含义 http.port 绑定端口的范围 默认9200-9300 http.publish_port 客户端与节点交互时需要使用的端口。这一配置在集群节点处于防火墙后时很有用，默认和http.port中分配的端口一致。 http.bind_host 绑定http服务的host地址，默认和http.host(如果设置了)或者network.bind_host一致 http.publish_host 客户端访问的host地址，默认和http.host(如果设置了)或者network.public_host一致 http.host 用来设置http.bind_host和http.publish_host,默认为http.host或者network.host http.max_content_length 设置请求内容的最大大小。默认100mb。如果设置的数值超过了Integer.MAX_VALUE,会被重置为100mb。 http.max_initial_line_length HTTP请求URL的最大长度，默认4kb http.max_header_size 请求头的最大大小，默认8kb http.compression 是否支持压缩(使用Accept-Encoding)，默认false http.compression_level 定义使用的压缩级别，默认为6 http.cors.enabled 是否允许跨域请求。默认为false http.cors.allow-origin 定义允许哪些源请求。可以使用正则表达式，例如/https?:\\/\\/localhost(:[0-9]+)?/可设置支持本地HTTP和HTTPS请求。也可以设置为*,但是会存在安全隐患，因为任何来源都可访问Elasticsearch(以下简称为Es)实例。 http.cors.max-age 浏览器会发送一个“预检”的OPTIONS请求，来检查CORS设置。max-age定义应该缓存多长时间的结果。默认为1728000（20天） http.cors.allow-methods 定义了允许的请求方式，默认允许OPTIONS, HEAD, GET, POST, PUT, DELETE http.cors.allow-headers 定义了允许的请求头信息。默认允许X-Requested-With, Content-Type, Content-Length http.cors.allow-credentials 是否返回设置的Access-Control-Allow-Credentials头信息。默认为false http.detailed_errors.enabled 是否输出详细的错误信息和堆栈。默认为true http.pipelining 是否启用HTTP管道支持, 默认为true http.pipelining.max_events 在一个HTTP连接被关闭之前内存队列中允许的最大的事件数量，默认为10000 该模块也可使用一些公共的网络配置(见网络设置一节)。 禁用HTTPHTTP模块可以通过将http.enable设置为false来禁用。Es节点(和Java客户端)的内部通信使用transport接口，而非HTTP。这意味着我们可以将不接受直接REST请求的节点的HTTP禁用。比如，可以将数据节点的http禁用，创建非数据节点用来处理所有的REST请求。需要注意的是，不能向一个已经禁用了HTTP的节点直接发送任何REST请求。 Indices(索引模块)官网对应链接：Indices这一模块可以对所有索引的索引相关配置进行全局控制。相关的配置如下： Circuit breaker(断路器)官网对应链接：Circuit breaker该模块用来限制内存的使用，避免出现内存溢出。Es中包含多个Circuit breaker(断路器)用来阻止可能造成OutOfMemoryError异常的操作。此外，还有一个父级别断路器限制了可以使用的总内存。这些配置都可通过Cluster-update-settings动态更新。父断路器父级别的断路器可以通过indices.breaker.total.limit来设置，默认是JVM堆的70% Filed data断路器允许Es提前估计加载一个字段需要的内存，然后检查加载需要的fielddata会不会导致总的内存大小超过设置的百分比。这样可以预防在加载的过程中产生异常。默认的限制是60%的JVM堆，可以通过以下参数配置。indices.breaker.fielddata.limit：限制fielddata所能占用的最大内存，默认为JVM堆的60%indices.breaker.fielddata.overhead:一个常量。es将使用这个值乘以field实际的大小作Field估算值，默认为1.03请求断路器允许Es阻止使用内存超过限制的请求。indices.breaker.request.limit:默认JVM堆的40%indices.breaker.request.overhead:一个常量。所有请求的预估内存乘以这个常量就是最终的估计值。默认为1 Fielddata cache(字段数据缓存)限制内存中的数据缓存可以使用多大的堆内存field data缓存主要用于针对一个字段排序和做聚合计算。为了快速的访问某些值，Es会将这些字段值加载到内存中。需要注意的是将字段加载到内存很耗费资源，所以官方建议保证有足够的内存，并且保持所有字段被加载。field data内存的大小可通过indices.fielddata.cache.size配置项控制。要注意的是，当这个缓存不够用时，为了腾出空间给新的缓存，原来缓存的字段会被挤出来，这会导致系统性能下降。indices.fielddata.cache.size:field data缓存的最大值。可以设为节点堆空间的30%，也可设置为一个确定的值，比如12GB。默认无限大，生产环境要注意设置这个值。 注意：这些静态配置需要在集群的每一个节点上设置。 监控field data可以通过Node Stats API监控内存使用情况。 Node query cache(查询缓存)配置缓存查询结果可以使用多少堆内存查询缓存负责对查询结果进行缓存。每一个节点都有一个查询缓存，由所有分片共享。缓存采用LRU机制，将最近最少使用的内容替换成新数据。查询缓存只会缓存filter的内容。下面的配置需要在集群的每一个节点上配置。indices.queries.cache.size: 控制过滤结果缓存的大小。默认是10%。也可设置为一个确定的值，如512mb。 Indexing buffer(索引缓冲)控制分配多少内存给索引进程索引缓冲用来存储新索引的文档。当缓冲区满了时，缓冲的文档会被写到磁盘的一个段，划分到该节点的所有分片上。以下这些静态配置需要在集群的每一个节点上设置。 配置项 含义 indices.memory.index_buffer_size 设置索引缓冲区的大小。可设置一个百分比或者字节大小。默认为10%，意味着节点的10%的 indices.memory.min_index_buffer_size 如果indices.memory.index_buffer_size被设置成了一个百分比，本配置项可以用来代表缓冲区的最小值，默认为48mb。 indices.memory.max_index_buffer_size 如果indices.memory.index_buffer_size被设置成了一个百分比，本配置项可以用来代表缓冲区的最大值，默认无限大。 indices.memory.min_shard_index_buffer_size 为每个分片自己的索引缓冲区设置最小值。默认4mb Shard request cache(分片请求缓存)控制分片级别的查询缓存的行为。当一个搜索请求是针对一个索引或者多个索引的时候，每一个涉及到的分片都会在本地进行搜索，然后把结果返回到协调节点，在由协调节点把这些结果合并到一起。由于分片缓存模块会将本地的查询结果缓存，所以频率高的搜索请求会立刻返回结果。 注意：目前，请求缓存只缓存查询条件size=0的搜索，缓存的内容有hits.total, aggregations,suggestions，而不缓存原始的hits。并且通过now查询的结果也不缓存。 只缓存查询条件size=0的搜索原因如下(引用自ELKstack-guide-cn):ES对请求的处理过程是有不同类型的，默认的叫 query_then_fetch。在这种情况下，各数据节点处理检索请求后，返回的是只包含文档id和相关性分值的结果，这一段处理，叫做query阶段；汇聚到这份结果后，按照分值排序，得到一个全集群最终需要的文档id，再向对应节点发送一次文档获取请求，拿到文档内容，这一段处理，叫做 fetch阶段。两段都结束后才返回响应。此外，还有DFS_query_then_fetch类型，提高小数据量时的精确度;query_and_fetch类型，在有明确routing时可以省略一个数据来回;count类型，不关心文档内容只需要计数时省略 fetch阶段;scan类型，批量获取数据省略query阶段，在reindex时就是使用这种类型。回到query cache，这里这个query，就是处理过程中query阶段的意思。各个节点上的数据分片，会在处理完query阶段时，将得到的本分片有关该请求的计数值，缓存起来。根据上面的请求类型介绍，显然,只有当?search_type=count的时候，这个query cache才能起到作用。缓存失效在分片数据真正发生变化时刷新索引分片，缓存的结果会自动失效。刷新间隔越长缓存的数据越多。当缓存满了的时候，会将最少使用的数据删除。缓存可以通过clear-cache API手动设置过期。 1curl -XPOST 'localhost:9200/kimchy,elasticsearch/_cache/clear?request_cache=true' 默认启动缓存分片请求缓存默认是不启动的，但可以在创建新的索引时通过下面的方式启动： 123456curl -XPUT localhost:9200/my_index -d'&#123; \"settings\": &#123; \"index.requests.cache.enable\": true &#125;&#125; 也可以通过update-settings API为就索引动态的启动和关闭缓存。 12curl -XPUT localhost:9200/my_index/_settings -d'&#123; \"index.requests.cache.enable\": true &#125; 为每个请求启动缓存可以在请求时通过请求参数request_cache来为每个请求启动和关闭缓存。1234567891011curl 'localhost:9200/my_index/_search?request_cache=true' -d'&#123; \"size\": 0, \"aggs\": &#123; \"popular_colors\": &#123; \"terms\": &#123; \"field\": \"colors\" &#125; &#125; &#125;&#125; 缓存设置缓存是在节点级别管理，默认JVM堆内存的1%。可在config/elasticsearch.yml文件中更改。1indices.requests.cache.size: 2% 也可以通过indices.requests.cache.expire设置缓存过期时间，但是没有必要，因为旧的结果会在索引刷新时自动失效。 检测缓存使用可通过indices-stats API检测索引中缓存的使用情况1curl 'localhost:9200/_stats/request_cache?pretty&amp;human' 或通过nodes-stats API查看节点的使用情况。1curl 'localhost:9200/_nodes/stats/indices/request_cache?pretty&amp;human' Indices Recovery(索引恢复)限制分片恢复进程的资源以下的配置用来管理恢复策略： 配置项 含义 indices.recovery.concurrent_streams 默认是3 indices.recovery.concurrent_small_file_streams 默认2 indices.recovery.file_chunk_size 默认512kb indices.recovery.translog_ops 默认1000 indices.recovery.translog_size 默认512kb indices.recovery.compress 默认true indices.recovery.max_bytes_per_sec 默认40mb 这些配置都可通过Cluster-update-settings动态更新。 TTL interval控制过期文档的删除设有ttl值的文档会在过期之后被删除。以下动态配置控制了删除文档的检查间隔，和批量删除的大小。indices.ttl.interval：删除进程启动间隔。默认60sindices.ttl.bulk_size：删除进程的数量。默认为1000 NetWork Settings(网络设置)Es默认只和localhost绑定。如果想要在多个服务器上启动生产环境的集群需要配置一些基本的网络设置。 注意：要小心使用网络配置，不要将不受保护的节点暴露在公共网络中。 常用的网络设置 配置项 含义 network.host 将节点绑定到设置的hostname或ip地址，并通知集群中的其他节点。该配置项接受IP地址，主机名，一些特定值(见下一个表)和由上面几项组成的数组。默认为_local_。 discovery.zen.ping.unicast.hosts 如果一个节点加入一个集群，需要知道集群中其他节点hostname和ip地址。本配置项为节点提供了其他节点的初始列表。默认[&quot;127.0.0.1&quot;,&quot;[::1]&quot;] http.port 为HTTP请求绑定端口，可设置单个端口，也可设置一个范围。如果设定了一个范围，节点会绑定在范围中第一个可用的端口。默认9200-9300。 transport.tcp.port 节点间内部通信绑定的端口，可设置单个端口，也可设置一个范围。如果设定了一个范围，节点会绑定在范围中第一个可用的端口。默认9300-9400 network.host可使用的一些特殊值 特殊值 含义 _[networkInterface]_ 指定网卡的IP地址，如_en0_ _local_ 本机ip地址，如127.0.0.1 _site_ 任意一个site-local地址，如192.168.0.1 _global_ 任意一个globally-scoped地址，如8.8.8.8 IPv4 vs IPv6以上特殊值默认在IPV4和IPv6下均可使用，可以通过:ipv4和:ipv6标识符来做限制。例如,_en0:ipv4_。 高级网络设置常用网络设置一节中提到的network.host配置项只是一个为了同时设置band_host和publish_host的快捷设置。为了一下更复杂的情况，比如在一个代理服务器后运行节点，可能需要一些不同的配置。 配置项 含义 network.bind_host 设置节点绑定的ip地址，用来监听请求。默认network.host。 network.publish_host 配置其他节点与本节点通信的地址，默认为network.bind_host中的最佳地址。 以上配置都和network.host一样，可配置ip地址，hostname和某些特殊值。 高级TCP设置任何使用TCP的模块（如HTTP和Transport）共享以下的配置。 配置项 含义 network.tcp.no_delay 是否启用TCP no delay。默认为true network.tcp.keep_alive 是否启用TCP keep alive。默认为true network.tcp.reuse_address 一个地址是否可以重复使用 network.tcp.send_buffer_size TCP发送缓冲区的大小，默认不设置 network.tcp.receive_buffer_size TCP接收缓冲区的大小，默认不设置 Transport和HTTP协议Es会基于上面的配置暴露两种网络协议，它们也可以进一步独立配置。TCP transport 用于节点之间通信 具体可见Transport模块一节。HTTP 用于暴露基于JSON的http接口。具体可见HTTP模块一节。 都看到这了，听首歌再走吧。分享首适合抖腿的歌，写博客时听这种歌真是分分钟都要把键盘按穿。。。","raw":null,"content":null,"categories":[{"name":"elasticsearch","slug":"elasticsearch","permalink":"http://yemengying.com/categories/elasticsearch/"}],"tags":[{"name":"elasticsearch","slug":"elasticsearch","permalink":"http://yemengying.com/tags/elasticsearch/"}]},{"title":"疯狂动物城","slug":"zootopia","date":"2016-03-15T04:44:12.000Z","updated":"2016-03-15T13:08:24.000Z","comments":true,"path":"2016/03/15/zootopia/","link":"","permalink":"http://yemengying.com/2016/03/15/zootopia/","excerpt":"真的是太喜欢疯狂动物城这部电影了，二刷之后还是想去电影院接着看，对这种毛茸茸的小动物真是一点抵抗力都没有，尤其是苏苏的狐尼克。放点网上搜来的图(权侵删)，方便看到它们，哇咔咔咔咔。","keywords":null,"text":"真的是太喜欢疯狂动物城这部电影了，二刷之后还是想去电影院接着看，对这种毛茸茸的小动物真是一点抵抗力都没有，尤其是苏苏的狐尼克。放点网上搜来的图(权侵删)，方便看到它们，哇咔咔咔咔。 蠢萌蠢萌，慢的出奇，戳中笑点的树懒flash 被圈饭的兔狐CP 最爱的狐尼克 勇敢的兔朱迪 致敬教父的Mr. Big 少女心的豹警官 大合照 从冰雪奇缘到超能陆战队再到疯狂动物城，不得不说迪斯尼的动画越来越好看了。好的动画片真的是老少皆宜的，让人在捧腹大笑的同时又能有所思考，不管是关于消除偏见，梦想还是成长~~~~。","raw":null,"content":null,"categories":[{"name":"随笔","slug":"随笔","permalink":"http://yemengying.com/categories/随笔/"}],"tags":[{"name":"随笔","slug":"随笔","permalink":"http://yemengying.com/tags/随笔/"},{"name":"电影","slug":"电影","permalink":"http://yemengying.com/tags/电影/"}]},{"title":"Java 8 --行为参数化(behavior parameterization)","slug":"Java-8-行为参数化-behavior-parameterization","date":"2016-02-20T11:33:21.000Z","updated":"2016-04-22T13:44:59.000Z","comments":true,"path":"2016/02/20/Java-8-行为参数化-behavior-parameterization/","link":"","permalink":"http://yemengying.com/2016/02/20/Java-8-行为参数化-behavior-parameterization/","excerpt":"根据书 &lt;&lt; Java 8 in action &gt;&gt;第二章的一个例子整理。书中通过一个例子，讲述了如何利用behavior parameterization来应对不停变化的需求。想想之前自己写的工具类，真是大写的Low啊。。。。 题外话：要时刻谨记 Later equals never,Later equals never,Later equals never！！！！！！！","keywords":null,"text":"根据书 &lt;&lt; Java 8 in action &gt;&gt;第二章的一个例子整理。书中通过一个例子，讲述了如何利用behavior parameterization来应对不停变化的需求。想想之前自己写的工具类，真是大写的Low啊。。。。 题外话：要时刻谨记 Later equals never,Later equals never,Later equals never！！！！！！！ 行为参数化在软件开发中，一个众所周知的问题就是无论你做什么,用户的需求总会改变。举个栗子，假设要做一个帮助农场主理解库存的应用。一开始，农场主可能想有一个在所有库存中找出所有绿色苹果的功能。但是第二天他可能会告诉你他还想要找到所有重量大于150g的苹果。两天后，他可能又提出找到所有绿色的并且重量大于150g的苹果。在面对这些相似的新功能时，我们都想尽可能的减少开发量。behavior parameterization是用来处理频繁更改的需求的一种软件开发模式，可以将一段代码块当做参数传给另一个方法，之后执行。这样做的好处是，方法的行为可以由传入的代码块控制。 例子下面通过农场应用来看看面对不断改变的需求如何将代码写的更灵活。先实现第一个功能:从一个list中过滤出所有的绿色苹果,听起来是不是很简单。 版本1 ： 过滤出绿色苹果最开始想到的解决办法可能长下面的样子： 12345678910public static List&lt;Apple&gt; filterGreenApples(List&lt;Apple&gt; inventory)&#123; List&lt;Apple&gt; result = new ArrayList&lt;&gt;(); // An accumulator list for apples for(Apple apple : inventory)&#123; if( \"green\".equals(apple.getColor()))&#123; // Select only green apples result.add(apple); &#125; &#125; return result; &#125; 上面的方法可以过滤出绿色的苹果，但是如果农场主还想知道红色的苹果呢？一个很幼稚的做法是将上面的方法复制一遍，命名为filterRedApples，更改一下if语句。但如果还想知道黄色的呢？一个好的做法是：试着抽象。 版本2 ： 将颜色作为参数可以在方法中加入颜色作为参数，使代码更灵活。 123456789public static List&lt;Apple&gt; filterApplesByColor(List&lt;Apple&gt; inventory,String color) &#123; List&lt;Apple&gt; result = new ArrayList&lt;&gt;(); for (Apple apple: inventory)&#123; if ( apple.getColor().equals(color) ) &#123; result.add(apple); &#125; &#125; return result;&#125; 这样就可以灵活的根据颜色来筛选。这时农场主又提出了根据重量筛选，于是参照上面根据颜色筛选的方法又新增了一个根据重量筛选的方法，如下： 123456789public static List&lt;Apple&gt; filterApplesByWeight(List&lt;Apple&gt; inventory,int weight) &#123; List&lt;Apple&gt; result = new ArrayList&lt;&gt;(); for (Apple apple: inventory)&#123; if ( apple.getWeight()&gt;weight ) &#123; result.add(apple); &#125; &#125; return result;&#125; 这是一个解决办法，但考虑到苹果有许多其它特性，如果针对每一特性的筛选都复制一个方法，违背了DRY(don’t repeat yourself)原则.我们可以将颜色和重量结合到一个方法，并通过一个标记来指明想要进行过滤的是颜色还是重量(这样做其实很不好，之后会解释)。 版本3 ： 在一个方法中过滤想要过滤的属性下面在一个方法中根据flag值的不同过滤不同的属性(这样做法很不好)。 12345678910public static List&lt;Apple&gt; filterApples(List&lt;Apple&gt; inventory,String color, int weight, boolean flag)&#123; List&lt;Apple&gt; result = new ArrayList&lt;&gt;(); for(Apple apple : inventory)&#123; if((flag&amp;&amp;apple.getColor().equals(color)) || (!flag &amp;&amp; apple.getWeight() &gt; weight))&#123; result.add(apple); &#125; &#125; return result; &#125; 上面的代码很丑陋而且也没有解决需求变化的问题，比如如果农场主还想要根据大小，产地，形状来筛选就不适用了。 版本4 ： 根据抽象约束过滤一个更好的解决办法是将过滤的标准抽象出来，我们先定义一个接口作为抽象的选择标准.123public interface ApplePredicate&#123; boolean test(Apple apple);&#125; 接下来就可以定义多个ApplePredicate接口的实现类来代表不同的过滤标准。如下图: 12345678910111213//select only heavy applepublic class AppleHeavyWeightPredicate implements ApplePredicate&#123; public boolean test(Apple apple)&#123; return apple.getWeight() &gt; 150; &#125;&#125;//select only green applepublic class AppleGreenColorPredicate implements ApplePredicate&#123; public boolean test(Apple apple)&#123; return \"green\".equals(apple.getColor); &#125;&#125; 上面每一个实现了ApplePredicate接口的类都代表了一种筛选策略。在此基础上，我们可以将筛选方法修改成下面的样子,将ApplePredicate作为参数传入。 123456789public static List&lt;Apple&gt; filterApples(List&lt;Apple&gt; inventory, ApplePredicate p)&#123; List&lt;Apple&gt; result = new ArrayList&lt;&gt;(); for(Apple apple : inventory)&#123; if(p.test(apple))&#123; result.add(apple); &#125; &#125; return result;&#125; 现在的筛选方法比第一个版本灵活多了，如果想改变筛选标准，只需创建不同的ApplePredicate对象，并传入filterApples方法即可。例如新增了选出红色并且重量大于150g的苹果的需求，我们可以创建一个实现ApplePredicate接口的类即可，代码如下:1234567public class AppleRedAndHeavyPredicate implements ApplePredicate&#123; public boolean test(Apple apple)&#123; return \"red\".equals(apple.getColor()) &amp;&amp; apple.getWeight() &gt; 150; &#125;&#125;List&lt;Apple&gt; redAndHeavyApples = filter(inventory, new AppleRedAndHeavyPredicate()); 但是上面的实现有一个缺点，就是太啰嗦了，每新增一个筛选标准都要新增一个类。下面来继续优化一下。 版本5 ： 使用匿名类匿名类是没有名字的类，使用匿名类可以创建一个临时的实现。下面的代码展示了如何利用匿名类创建实现了ApplePredicate的对象。12345List&lt;Apple&gt; redApples = filterApples(inventory, new ApplePredicate()&#123; public boolean test(Apple apple)&#123; return \"red\".equals(apple.getColor()); &#125;&#125;); 但是尽管匿名类解决了为一个接口声明多个实现类的问题，使用匿名类还不足够好。使用匿名类代码看起来有些笨重，可读性差，而且有一些开发者对匿名类感到困惑。下面我们使用Java 8引入的lambda表达式使代码看起来更加简洁一点。 版本6 ： 使用lambda表达式我们可以使用lambda表达式简化代码. 1List&lt;Apple&gt; result = filterApples(inventory,(Apple apple) -&gt; \"red\".equals(apple.getColor())); 最终版 ： 使用泛型，抽象列表的类型我们可以继续做一些抽象。目前，filterApples方法只可以过滤元素类型为Apple的List。我们可以将列表的类型抽象出来，使得我们的过滤方法变得更加通用，代码如下：12345678910111213public interface Predicate&lt;T&gt;&#123; boolean test(T t);&#125;pucblic static &lt;T&gt; List&lt;T&gt; filter(List&lt;T&gt; list, Predicate&lt;T&gt; p)&#123; List&lt;T&gt; result = new ArrayList&lt;&gt;(); for(T e: list)&#123; if(p.test(e))&#123; result.add(e); &#125; &#125; return result;&#125; 这样就可以对多种类型的list进行过滤了： 123List&lt;Apple&gt; redApples = filter(inventory, (Apple apple) -&gt; \"red\".equals(apple.getColor()));List&lt;String&gt; evenNumber = filter(numbers, (Integer i) -&gt; i%2 == 0); 终于over了，拖延癌果真已经到了晚期。。。。。","raw":null,"content":null,"categories":[{"name":"java","slug":"java","permalink":"http://yemengying.com/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"http://yemengying.com/tags/java/"}]},{"title":"[译]Java 8中HashMap和LinkedHashMap如何解决冲突","slug":"译-Java中HashMap和LinkedHashMap如何解决冲突","date":"2016-02-03T08:23:39.000Z","updated":"2016-04-22T13:44:14.000Z","comments":true,"path":"2016/02/03/译-Java中HashMap和LinkedHashMap如何解决冲突/","link":"","permalink":"http://yemengying.com/2016/02/03/译-Java中HashMap和LinkedHashMap如何解决冲突/","excerpt":"原文来自一个java大牛的博客 原文地址http://javarevisited.blogspot.jp/2016/01/how-does-java-hashmap-or-linkedhahsmap-handles.html 博客讲解了Java 8中HashMap和LinkedHashMap是如何解决冲突的。","keywords":null,"text":"原文来自一个java大牛的博客 原文地址http://javarevisited.blogspot.jp/2016/01/how-does-java-hashmap-or-linkedhahsmap-handles.html 博客讲解了Java 8中HashMap和LinkedHashMap是如何解决冲突的。 在Java 8 之前，HashMap和其他基于map的类都是通过链地址法解决冲突，它们使用单向链表来存储相同索引值的元素。在最坏的情况下，这种方式会将HashMap的get方法的性能从O(1)降低到O(n)。为了解决在频繁冲突时hashmap性能降低的问题，Java 8中使用平衡树来替代链表存储冲突的元素。这意味着我们可以将最坏情况下的性能从O(n)提高到O(logn)。在Java 8中使用常量TREEIFY_THRESHOLD来控制是否切换到平衡树来存储。目前，这个常量值是8，这意味着当有超过8个元素的索引一样时，HashMap会使用树来存储它们。这一改变是为了继续优化常用类。大家可能还记得在Java 7中为了优化常用类对ArrayList和HashMap采用了延迟加载的机制，在有元素加入之前不会分配内存，这会减少空的链表和HashMap占用的内存。这一动态的特性使得HashMap一开始使用链表，并在冲突的元素数量超过指定值时用平衡二叉树替换链表。不过这一特性在所有基于hash table的类中并没有，例如Hashtable和WeakHashMap。目前，只有ConcurrentHashMap,LinkedHashMap和HashMap会在频繁冲突的情况下使用平衡树。 什么时候会产生冲突HashMap中调用hashCode()方法来计算hashCode。由于在Java中两个不同的对象可能有一样的hashCode,所以不同的键可能有一样hashCode，从而导致冲突的产生。 总结 HashMap在处理冲突时使用链表存储相同索引的元素。 从Java 8开始，HashMap，ConcurrentHashMap和LinkedHashMap在处理频繁冲突时将使用平衡树来代替链表，当同一hash桶中的元素数量超过特定的值便会由链表切换到平衡树，这会将get()方法的性能从O(n)提高到O(logn)。 当从链表切换到平衡树时，HashMap迭代的顺序将会改变。不过这并不会造成什么问题，因为HashMap并没有对迭代的顺序提供任何保证。 从Java 1中就存在的Hashtable类为了保证迭代顺序不变，即便在频繁冲突的情况下也不会使用平衡树。这一决定是为了不破坏某些较老的需要依赖于Hashtable迭代顺序的Java应用。 除了Hashtable之外，WeakHashMap和IdentityHashMap也不会在频繁冲突的情况下使用平衡树。 使用HashMap之所以会产生冲突是因为使用了键对象的hashCode()方法，而equals()和hashCode()方法不保证不同对象的hashCode是不同的。需要记住的是，相同对象的hashCode一定是相同的，但相同的hashCode不一定是相同的对象。 在HashTable和HashMap中，冲突的产生是由于不同对象的hashCode()方法返回了一样的值。 以上就是Java中HashMap如何处理冲突。这种方法被称为链地址法，因为使用链表存储同一桶内的元素。通常情况HashMap，HashSet，LinkedHashSet，LinkedHashMap，ConcurrentHashMap，HashTable，IdentityHashMap和WeakHashMap均采用这种方法处理冲突。 从JDK 8开始，HashMap，LinkedHashMap和ConcurrentHashMap为了提升性能，在频繁冲突的时候使用平衡树来替代链表。因为HashSet内部使用了HashMap，LinkedHashSet内部使用了LinkedHashMap，所以他们的性能也会得到提升。 相关阅读Data Structure and Algorithm in JavaJava Performance The Definitive Guide","raw":null,"content":null,"categories":[{"name":"java","slug":"java","permalink":"http://yemengying.com/categories/java/"},{"name":"hashmap","slug":"java/hashmap","permalink":"http://yemengying.com/categories/java/hashmap/"}],"tags":[{"name":"java","slug":"java","permalink":"http://yemengying.com/tags/java/"},{"name":"翻译","slug":"翻译","permalink":"http://yemengying.com/tags/翻译/"}]},{"title":"最近看的书","slug":"最近看的书","date":"2016-01-19T06:34:13.000Z","updated":"2016-04-22T13:44:30.000Z","comments":true,"path":"2016/01/19/最近看的书/","link":"","permalink":"http://yemengying.com/2016/01/19/最近看的书/","excerpt":"自从去年8月份之后真是变成了个爱看书のgirl，算是*%^&amp;#$带来的唯一好处吧，是时候整理一发啦。不过，要按什么分类呢，技术和非技术，看完和没看完，好看和不好看还是外文和中文？好乱。。。。 算了 还是不分了随便列吧。。。。","keywords":null,"text":"自从去年8月份之后真是变成了个爱看书のgirl，算是*%^&amp;#$带来的唯一好处吧，是时候整理一发啦。不过，要按什么分类呢，技术和非技术，看完和没看完，好看和不好看还是外文和中文？好乱。。。。 算了 还是不分了随便列吧。。。。 Flipped(怦然心动)一本讲两个小学生初恋的英文小说，适合放松的时候看看。虽然已经看过了电影，再看小说还是觉得很美好，成功唤醒了我那颗沉睡已久的少女心。女主性格超级可爱，男主虽然一开始挺烦人的，不过后期的转变还是不错的，撩妹技能满分，还有女的爸爸和男主的爷爷也都是很有哲理的人。里面的句子都挺简单的，用来学英语也不错。 淘宝技术这十年很多地方都有推荐这本书，就买了，不过看完倒也没觉得多好看，里面关于技术的地方讲的很浅，所以指望着学到什么技术还是别看了,当故事书看还是不错的。现在书的内容已经记不太清了，就记得两句话，好的架构都是一步步演化来的和再牛B的人也都有一段苦B的经历。 清醒思考的艺术左耳朵耗子来做技术分享时推荐的，里面是一个个的小故事，通过讲故事的方式来告诉读者思考时容易犯的错。读起来挺轻松的，可以睡前看一个小故事。不过吧。。。。道理都懂，想做到清醒思考还是挺难的。 灿烂千阳(A THOUSAND SPLENDID SUNS)是《追风筝的人》作者的另一本小说，没看过追风筝的人，不过名气好像挺大的。灿烂千阳主要讲了两个阿富汗少女悲惨的一生，虽然莱拉结局还算不错，不过整体看还是挺惨的，都是战争害的。觉得整本书最感人的地方不是莱拉和玛利亚姆互相帮助和莱拉和塔里克的爱情，而是书的结尾莱拉发现了玛利亚姆父亲留给她的东西，戳中泪点啊。。。。。看完了之后觉得现在生活真心很幸福的啊。 深入理解Java虚拟机这本。。。。大概看了两三章，实在看不下去。。。不是书写的不好，是我技术渣看不太懂。。。还是先放放吧 从0到1 利用周末看完了，感觉作者说的都对，但对现在的我帮助不大，可能经历还不够吧。不过喜欢做开发也正是因为从0到1的创造一个产品的过程很interesting。 Linux Bible 9th Edition超实用的技术书，不过由于是英文的还是技术书，看的比较慢，才看到第六章，基本一章一个主题已经从使用shell看到管理进程了。真是每一章都有很大收获，比如以前查看进程就知道用ps aux，并不知道每个命令选项的具体意思。走过路过不要错过，linux学的好的也可以看看，查漏补缺啊。争取以一周一章的速度把它看完。有要电子书的可以留邮箱 哈哈。 Spring in Action 4th edition虽然一直在用spring，但是貌似一直没有系统完整的看过一本关于spring的书，正好从geekbook上爬下了这本就看看吧，查漏补缺，以前注入bean，一直用xml和利用注解自动注入的方式，借这个机会了解下利用JavaConfig是如何实现依赖注入的。令我吃惊的是，作者第二推荐的居然是JavaConfig，一直以为Xml的方式应该排第二呢。。。刚看到第三章，慢慢看吧。。。有要电子书的可以留邮箱。 The Martian(火星救援)看完电影再来看书，觉得书比电影好一点，当然电影也不差。男主实在令人折服，尤其是他遇到困难只想着怎么解决困难的精神。如果把我留在火星上，估计得死好几百回。。。。 偷影子的人一本治愈系的法国小说，喜欢封面的设计，内容挺平淡的，感觉前半部分比后面要好看。","raw":null,"content":null,"categories":[{"name":"随笔","slug":"随笔","permalink":"http://yemengying.com/categories/随笔/"}],"tags":[{"name":"随笔","slug":"随笔","permalink":"http://yemengying.com/tags/随笔/"},{"name":"书单","slug":"书单","permalink":"http://yemengying.com/tags/书单/"}]},{"title":"拥有自己的图书小金库","slug":"拥有自己的图书小金库","date":"2016-01-09T06:15:46.000Z","updated":"2016-04-23T01:59:14.000Z","comments":true,"path":"2016/01/09/拥有自己的图书小金库/","link":"","permalink":"http://yemengying.com/2016/01/09/拥有自己的图书小金库/","excerpt":"在找matering elasticsearch second edition这本书的时候，在许多可以免费下电子书的网站都没有找到，所以就买了Geekbook一个月的会员，为了不浪费充会员的钱，决定撸个脚本把全站的书都下下来,并用django搭个管理后台。和洪菊，卢神利用空闲时间忙活了快两周，终于有了自己的图书小金库，5000+的优质英文原版电子书，哇咔咔咔咔，这辈子的书都有了，放了一部分到github上。geekbook千万不要怪我们啊，谁让你不封我们的~~。项目地址： loadStyle(\"/hexo-github/style.css\"); loadStyle(\"/hexo-github/octicons/octicons.css\"); new Badge(\"#badge-container-giraffe0813-GeekBook-3d83e8f\", \"giraffe0813\", \"GeekBook\", \"3d83e8f\", false); 部分电子书地址: loadStyle(\"/hexo-github/style.css\"); loadStyle(\"/hexo-github/octicons/octicons.css\"); new Badge(\"#badge-container-Geek-Organization-geek-programming-books-643e0bd\", \"Geek-Organization\", \"geek-programming-books\", \"643e0bd\", false);","keywords":null,"text":"在找matering elasticsearch second edition这本书的时候，在许多可以免费下电子书的网站都没有找到，所以就买了Geekbook一个月的会员，为了不浪费充会员的钱，决定撸个脚本把全站的书都下下来,并用django搭个管理后台。和洪菊，卢神利用空闲时间忙活了快两周，终于有了自己的图书小金库，5000+的优质英文原版电子书，哇咔咔咔咔，这辈子的书都有了，放了一部分到github上。geekbook千万不要怪我们啊，谁让你不封我们的~~。项目地址： loadStyle(\"/hexo-github/style.css\"); loadStyle(\"/hexo-github/octicons/octicons.css\"); new Badge(\"#badge-container-giraffe0813-GeekBook-3d83e8f\", \"giraffe0813\", \"GeekBook\", \"3d83e8f\", false); 部分电子书地址: loadStyle(\"/hexo-github/style.css\"); loadStyle(\"/hexo-github/octicons/octicons.css\"); new Badge(\"#badge-container-Geek-Organization-geek-programming-books-643e0bd\", \"Geek-Organization\", \"geek-programming-books\", \"643e0bd\", false); 遇到的坑记录下遇到的坑 不然就忘了😂 只带cookie 无法下载本来以为只要带着登录之后的cookie请求下载的地址(eg:https://www.geekbooks.me/books/56/48/c1955c13518f994167b11f7b7279/amazon_ec2_cookbook.pdf) 就可以下载了，不过发现下下来的并不是书，而是网站上书的详情页的html。受到博客Course抓站小结 的启发，又研究了一下请求的header。发现除了要带cookie之外，还要带有user_agent和Referer，refer是表示从哪个页面访问当前链接。所以修改了下代码，在请求头中加入user-agent和referer之后，问题就解决了,部分代码如下1234567cookie = cookielib.MozillaCookieJar()# get cookie from filecookie.load('../data/cookie4geek.data', ignore_discard=True, ignore_expires=True)handler = urllib2.HTTPCookieProcessor(cookie)opener = urllib2.build_opener(handler)# add headeropener.addheaders = [('User-agent', 'Mozilla/5.0'), (\"Referer\", url)] 下载文件的时候不显示进度可以下载文件之后，希望可以在下载文件的时候显示下载进度，让我们知道他在工作。。。。直接在stackoverflow上抄了段代码，这个问题也愉快的解决了。12345678910111213141516171819202122u = opener.open(\"https://www.geekbooks.me\" + url)print \"Preparing to download...\"# f with directoryif os.path.exists(conf_books_dir + category + \"/\" + file_name) and detect_book( (conf_books_dir + category + \"/\" + file_name)): continuef = open(conf_books_dir + category + \"/\" + file_name, 'wb')meta = u.info()file_size = int(meta.getheaders(\"Content-Length\")[0])print \"Downloading: %s Bytes: %s\" % (file_name, file_size)file_size_dl = 0block_sz = 8192while True: buffer = u.read(block_sz) if not buffer: break file_size_dl += len(buffer) f.write(buffer) status = r\"%10d [%3.2f%%]\" % (file_size_dl, file_size_dl * 100. / file_size) status = status + chr(8) * (len(status) + 1) print status,f.close() 一本一本下载速度太慢这个只能果断上多线程了。。。123456789101112131415161718def download_work(): f = open(\"../data/detailurl.txt\", \"r\") books = [] destDir = \"\" tmp = \"\" for line in f: if not (line.strip()).startswith(\"/\"): tmp += \"/\" + line.strip() destDir = tmp else: # desDir book = Book(destDir, line.strip()) books.append(book) tmp = \"\" pool = threadpool.ThreadPool(conf_thread_count) reqs = threadpool.makeRequests(lambda book: book.download(), books) [pool.putRequest(req) for req in reqs] pool.wait() 无法展示下载书的具体信息除了将书下载下来，还想将书的一些基本信息保存下来，比如:作者，简洁，出版年份，封面，标签等等。。最好可以根据作者，题目进行搜索。本来想自己写个网站出来，但是又没有时间。还好之前学叔推荐过django，用django搭个管理后台简直不要太方便好么，配置nginx，supervisor的时间都比写代码的时间长👅，还可以很方便定义想搜索的字段和想展示的字段。样式是丑了一丢丢，但自己用也无所谓。 成品 Summary依靠空闲时间可以做点想做的事，也是蛮好的~~。用python写脚本真的很方便，基本不用自己造轮子，用它自带的模块就可以完成了。用django搭管理后台也是快的不要不要的。一周多的时间换4000+的书很值啊，但是。。。。服务器+存储平均一天的成本就要10块。。。是不是得想个法子，看能不能用这些电子书挣点钱啊。。。。想到这。。。突然没那么开心了。。。","raw":null,"content":null,"categories":[{"name":"python","slug":"python","permalink":"http://yemengying.com/categories/python/"}],"tags":[{"name":"python","slug":"python","permalink":"http://yemengying.com/tags/python/"},{"name":"爬虫","slug":"爬虫","permalink":"http://yemengying.com/tags/爬虫/"},{"name":"django","slug":"django","permalink":"http://yemengying.com/tags/django/"}]},{"title":"读书笔记-Linux Bible 9th Edition之进程大法好","slug":"读书笔记-Linux-Bible-9th-Edition之进程大法好","date":"2015-12-24T09:56:03.000Z","updated":"2016-04-22T13:43:24.000Z","comments":true,"path":"2015/12/24/读书笔记-Linux-Bible-9th-Edition之进程大法好/","link":"","permalink":"http://yemengying.com/2015/12/24/读书笔记-Linux-Bible-9th-Edition之进程大法好/","excerpt":"根据Linux Bible第九版第六章整理的读书笔记，记录linux系统下如何管理进程 Linux是一个支持多用户和多任务的操作系统，多任务是指可以同时运行多个程序，而每个运行程序的一个实例被称作一个进程。Linux系统提供了可以让我们列出正运行进程，杀死进程，监听系统使用情况的工具。 相关博客:Linux Bible 9th Edition之使用shellLinux Bible 9th Edition之玩转文本文件Linux Bible 9th Edition之文件系统","keywords":null,"text":"根据Linux Bible第九版第六章整理的读书笔记，记录linux系统下如何管理进程 Linux是一个支持多用户和多任务的操作系统，多任务是指可以同时运行多个程序，而每个运行程序的一个实例被称作一个进程。Linux系统提供了可以让我们列出正运行进程，杀死进程，监听系统使用情况的工具。 相关博客:Linux Bible 9th Edition之使用shellLinux Bible 9th Edition之玩转文本文件Linux Bible 9th Edition之文件系统 理解进程一个进程是一个命令正在运行的实例。比如，系统中有一个vi命令，如果vi命令正在被15个不同的用户运行，那么就对应了15个不同的运行进程。一个进程在系统中通过进程Id(process ID)来标识，在当前系统中进程Id是独一无二的。换句话说，如果一个进程正在运行，那么其他进程都不能使用它的进程Id的数字作为自己的进程Id。但如果这个进程已经结束，那么他的进程Id可以被重新使用当做其他进程的进程Id。除了进程Id，进程还有一些其他属性。每个运行的进程都会关联一个指定的用户账号和用户组，这个账号决定了进程可以访问哪些系统资源。所以root用户运行的进程能比普通用户的进程访问更多的文件。对于一个Linux的管理员来说，管理进程的能力至关重要。因为有时，一些运行的进程会严重影响系统的性能，这一章会讲述如果根据内存和CPU的使用情况，定位和处理这些进程。 列出进程如果使用命令行列出当前系统运行的进程，ps命令是最老也是最常用的命令，而top命令不仅可以列出进程还可以更改进程的状态。如果使用的是GNOME，可以使用gnome-system-monitor来通过图形界面管理进程。 通过ps命令列出进程最常用的查看正在运行进程的工具就是ps命令，通过ps命令，我们可以查看正在运行的进程，它们使用的资源以及运行它们的用户。下面是ps命令的一个例子: 1234$ ps uUSER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND jake 2147 0.0 0.7 1836 1020 tty1 S+ 14:50 0:00 -bash jake 2310 0.0 0.7 2592 912 tty1 R+ 18:22 0:00 ps u 在上面的命令中，使用u选项会显示用户名和一些其他信息，比如进程是什么时候开始运行的，进程占用的内存和Cpu，命令运行的位置(TTY)等。上面的第一个进程说明了jake用户在登录之后打开了一个bash shell。第二进程显示了jake用户正在运行ps u命令。终端设备tty1正在被登录会话使用着。STAT这一列代表了进程的状态，R代表进程正在运行，S代表进程处于休眠状态。 STAT除了R和S之外还可以有别的值，D代表不可中断，R运行，S中断/休眠，T停止，Z僵死。如果后面有+号，代表在前台运行的进程。 USER列显示了运行这个进程的用户。PID列是进程的进程Id，每个进程都有一个独一无二的进程Id，在需要杀死一个进程或者为进程发送信号时使用。%CPU和%MEN两列显示了进程占用的CPU百分比和内存百分比。VSZ(virtual set size)展示了虚拟内存占用大小(单位：kb/kilobytes),RSS(reside set size)展示了实际内存占用大小(单位：kb/kilobytes)。VSZ和RSS的值可能不一样，因为VSZ是分配给进程的内存大小，而RSS是进程实际使用的内存大小，代表了不可交换的物理内存。START代表了进程启动的时间，TIME执行累计时间(如果占用cpu时间非常短不到一秒，会显示 0:00)。在Linux中，有些运行的进程是与终端无关的，这些进程通常在系统启动时开始运行，并且会持续运行，直到系统关闭。可以使用x选项查看与终端无关的进程。 分页查看与当前用户有关的所有运行进程 1$ ps ux | less 分页查看所有用户的运行的进程 1$ ps aux | less 管道符(“|”)会将第一个命令的输出当做第二个命令的输入，上面的例子中ps命令的输出会当做less命令的输入，这样就可以分页查看信息了。按空格键换页，按q退出。我们还可以自定义ps命令展示的信息，并按其中一列排序。使用-o选项，可以通过关键字指定想要展示的列。下面的例子就是指定ps展示进程Id(pid),用户名(username),用户Id(uid),用户组(group),组Id(gid),分配的虚拟内存(vsz),实际使用内存(rss),运行的命令(comm),默认情况下按进程Id排序。123$ ps -eo pid,user,uid,group,gid,vsz,rss,comm | less PID USER GROUP GID VSZ RSS COMMAND 1 root root 0 19324 1320 init 2 root root 0 0 0 kthreadd 如果想要按其他列排序可以使用sort=选项。例如，想查看那个进程占用了最多的内存，可以按rss排列，会按rss从低到高展示进程，如果想从高到底可以在前面加连字符。下面是例子：12345$ ps -eo pid,user,group,gid,vsz,rss,comm --sort=-rss | lessPID USER GROUP GID VSZ RSS COMMAND12005 cnegus cnegus 13597 1271008 522192 firefox5412 cnegus cnegus 13597 949584 157268 thunderbird-bin25870 cnegus cnegus 13597 1332492 112952 swriter.bin 通过top命令列出进程,修改进程使用top命令，会默认按占用CPU的时间展示进程，也可以按其他指标排序。如果定位到了一个异常的进程，可以使用top终止(kill)进程或修改其优先级(reprioritize)。如果想要能够终止所有的进程或更改所有进程优先级需要使用root user来运行top命令。如果只是想要展示进程，或者更改自己的进程，那么可以使用普通用户的身份。下图是使用top的例子，最上面列出了系统的基本信息，下面是每个运行进程的信息。从最上面的输出信息你可以知道系统启动了多长时间，目前用多少用户登入，在过去的1,5,10分钟内分别运行了多少条命令。除此之外还包括了当前有多少进程在运行，CPU占用多少，用多少可用的Swap和RAM。紧接着列出了每个进程的基本信息，按进程占用cpu百分比排列，默认情况下所有信息5秒钟刷新一次。 下面列出了在用top展示、修改进程时可用的一些操作： 按h看帮助选项，按任意键返回 按M按占用内存排列，按P返回按CPU排列 按数字1可以在所有cpu中切换，前提是你的系统中有多于一个cpu 按R将输出倒序排列 按u并输入一个用户名，展示指定用户的进程 下面是运行top命令时，如何终止进程或修改其优先级: 修改优先级：记下想要修改的进程的PID，之后按r输入线程对应的PID,再输入想要调整的值(-19 到 20)。 终止进程： 记下想要修改的进程的PID，之后按k输入线程对应的PID，之后输入15(终止)或9(强迫终止)。 题外话最近负能量太多了 赶紧听首我大少时的歌压压。","raw":null,"content":null,"categories":[{"name":"linux","slug":"linux","permalink":"http://yemengying.com/categories/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://yemengying.com/tags/linux/"},{"name":"读书笔记","slug":"读书笔记","permalink":"http://yemengying.com/tags/读书笔记/"}]},{"title":"读书笔记-Linux Bible 9th Edition之玩转文本文件","slug":"读书笔记-Linux-Bible-9th-Edition之玩转文本文件","date":"2015-11-30T07:04:46.000Z","updated":"2016-04-22T13:43:30.000Z","comments":true,"path":"2015/11/30/读书笔记-Linux-Bible-9th-Edition之玩转文本文件/","link":"","permalink":"http://yemengying.com/2015/11/30/读书笔记-Linux-Bible-9th-Edition之玩转文本文件/","excerpt":"根据书的第5章整理一下关于操作文本文件的常用命令。在Linux系统中许多信息都是在文本文件中管理的,所以熟练掌握对文本文件的更改，查找是很重要的。这一点，在出bug查找服务器日志时真是深有体会啊！😼😼 相关博客: Linux Bible 9th Edition之使用shell Linux Bible 9th Edition之文件系统 Linux Bible 9th Edition之进程大法好","keywords":null,"text":"根据书的第5章整理一下关于操作文本文件的常用命令。在Linux系统中许多信息都是在文本文件中管理的,所以熟练掌握对文本文件的更改，查找是很重要的。这一点，在出bug查找服务器日志时真是深有体会啊！😼😼 相关博客: Linux Bible 9th Edition之使用shell Linux Bible 9th Edition之文件系统 Linux Bible 9th Edition之进程大法好 使用vim和vi编辑文件 刚接触vi编辑器可能会觉得有点难，不过当你熟悉了之后可以只用键盘就能快速高效的编辑文件，无需使用鼠标或功能键。(如果觉得vi不适合你，可以选择其它的文本编辑器，比如:nano,gedit,jed,kate,kedit,mcedit,nedit…等等) 从最常见的打开文件的开始了解vi打开文件: 1$ vi test 如果这是一个空的文件，你会看到类似下图的东东。最上面闪烁的东东代表了光标的当前位置，最下面的一行显示了关于文件的一些信息,中间的”~”符号代表没有内容。当你看到这个界面可能会感觉不知所措，因为没有任何菜单，提示和图标来告诉你该做什么。更恐怖的是，你不能直接输入，否则会听见”嘟嘟”的声音。 添加文件内容不要怕,首先,需要了解两种主要的模式:命令模式(command)和编辑模式(input)。vi编辑器以命令模式启动，在添加或改变文本内容之前需输入命令来告诉vi你想要做什么(大小写敏感)。输入下面的命令就可以进入编辑模式，当编辑结束后，按Esc键就可以回到命令模式。 命令 作用 a 可以在光标右侧开始插入文本 A 可以在当前行的最后开始插入文本 i 可以在光标左侧开始插入文本 I 可以在当前行的最前面开始插入文本 o 在当前行下面 插入新的一行 O 在当前行上面 插入新的一行 当进入编辑模式时，屏幕下方会出现– INSERT –；编辑结束后，按Esc键就可以回到命令模式。不过如果输入了”:”符号，需要按两下Esc键 在文本中移动可以使用方向键可以在文本中移动光标，但还有一些小技巧可以让我们更方便的在文本中移动 命令 作用 w 光标移到下一个单词的开头(单词以spaces,tabs,标点界定) W 光标移到下一个单词的开头(单词以spaces,tabs界定) b 光标移到前一个单词的开头(单词以spaces,tabs,标点界定) B 光标移到前一个单词的开头(单词以spaces,tabs界定) 0(zero) 光标移到当前行的最前面 $ 光标移到当前行的最后 H 光标移到屏幕的左上角 M 移到中间行第一个字符 L 光标移到屏幕的左下角 删除，复制，更改文本了解了如何添加文本和移动光标是远远不够的，还需要知道如何删除，复制和更改文本。命令x,d,y,c等可以帮助我们删除和修改文本，这些命令也可以和移动光标的命令(上一个表格中提到的)或者数字配合使用来告诉编辑器确切的操作是什么。 命令 作用 x 删除光标所在位置的字符 X 删除光标所在位置的前一个字符 d? 删除一些文本 c? 更改一些文本 y? 复制一些文本 ?代表这些命令要和移动光标的命令配合着使用，下面是一些例子 命令 作用 dw 删除当前光标位置的后一个单词 db 删除当前光标位置的前一个单词 dd 删除当前一整行 c$ 更改(实际上是擦除)从当前位置到当前行最后的内容，并进入编辑模式 c0 更改(实际上是擦除)从当前位置到当前行最前面的内容，并进入编辑模式 yy 将当前行复制到buffer中 上面这些命令也可以和数字配合使用,下面是栗子🌰 命令 作用 3dd 删除当前行往下的三行 3dw 删除接下来的三个单词 5cl 删除接下来的5个字符，并进入编辑模式 粘贴可以使用命令p和P，将复制到buffer中的内容粘贴到文本中。p是将缓存区的内容粘贴到当前光标所在位置的下方，P是将缓存区的内容粘贴到当前光标所在位置的上方 在文件中跳跃 命令 作用 ctrl+f 向下一页 ctrl+b 向上一页 ctrl+d 向下一页半 ctrl+u 向上一页半 G 跳到最后一行 1G 跳到第一行 35G 跳到第35行 查找文本查找文本时,”/“和”?”分别对应向前和向后查找,也可以使用一些通配符，比如/The.*foot,?[pP]rint,查找之后可以按n和N来重复查找和按相反方向查找 命令 作用 /hello 向前查找单词”hello” ?goodbye 向后查找单词”goodbye” 使用ex模式当输入冒号,并且光标在最下方时就进入了ex模式，下面是一些在ex模式下查找，修改文本的栗子🌰 命令 作用 :g/local 查找local 并打印 :s/local/r 将local第一次出现的位置替换为r 退出vi以下的命令用来保存和退出文件 命令 作用 ZZ 保存修改 并退出vi :w 保存修改 但不退出vi :wq 与ZZ命令一样 :q 退出文件，该命令只有在没有未保存的修改下才起效 :q! 退出文件 不保存对文件的修改 查找文件 为了帮助用户更有效的查找他们的文件，linux系统提供了locate,find,grep三个命令，依次来看看他们的作用。 使用localte命令查找文件 大多数linux系统中，updatedb命令会每天执行一次，将系统中文件的名字存到数据库中。通过locate命令，我们可以查找存在在数据库中的文件的位置。相较于find命令，locate命令效率更高，因为它搜索数据库而不是整个文件系统。不过locate命令也有它的缺点，它并不能找到所有存放在系统的文件，因为并不是所有的文件都会存储于数据库中，/etc/updatedb.conf文件决定了哪些文件将存在于数据库中。另外，普通用户无法通过数据库查找那些他们在文件系统中没有权利查看的文件，比如，普通用户无法在/root目录下执行ls命令，那么他们也无法通过locate查找这个目录下的文件。如果用locate命令查找一个字符串，那么这个字符串可能出现在返回文件的路径的任意位置。举个栗子，查找passwd，结果可能为/etc/passwd,/usr/bin/passwd和其它路径包含passwd的文件。还需要注意的是，如果创建一个文件之后，希望立刻通过locate查找它，最好执行命令updatedb更新下数据库。 123456789101112$ locate .bashrc/etc/skel/.bashrc /home/cnegus/.bashrc# locate ./bashrc (身份不同 查找结果不同)/etc/skel/.bashrc /home/bill/.bashrc /home/joe/.bashrc /root/.bashrc$ locate -i muttrc（-i 忽略大小写） /etc/Muttrc /etc/Muttrc.local /usr/share/doc/mutt-1.5.20/sample.muttrc $ locate services (查找的字符串可能出现在文件路径中) /etc/services /usr/share/services/bmp.kmgio /usr/share/services/data.kmgio 中场休息，看看我家光洙 使用find命令查找文件 由于有许多不同的属性，find命令是查找文件的利器。当执行find命令时，它会搜索整个文件系统，这会造成find命令比locate命令耗时长，但同时也能让用户查找到系统中最新的文件。find命令最大的优点在于所有你能想到的文件的属性，都可以通过它查找，例如名字，拥有者，权限，大小，修改时间等等，也可以进行组合查找。 123456789101112$ find (列出当前目录下所有的文件和目录)$ find /etc (列出/etc目录下所有的文件和目录，权限不足时会报错)$ find -ls (列出文件的拥有者，权限，大小等信息)$ find /etc -name passwd（根据名字查找）$ find /etc -iname '*passwd*' （可以使用通配符）$ find /bigdata -size +10G （查找大小大于10G的文件）$ find /smalldata -size -5M (查找大小小于5M的文件)$ find /home -user chris -ls (输出/home目录下拥有者是chris的文件的详细信息)$ find /home -user chris -or -user joe -ls (输出/home目录下拥有者是chris或joe的文件的详细信息)$ find /home -not -user root -ls (输出/home目录下拥有者不是root的文件的详细信息)$ find /bin -perm 755 -ls（通过权限查找）$ find . -perm -002 -type f -ls （通过类型查找） find命令还有一个很棒的特性，可以使用-excute和-ok选项可以在查找到的任何文件上执行命令。excute选项会直接在每个找到的文件上执行命令，不会询问是否执行。而ok选项会在每个文件执行命令前询问是否执行。 1234$ find /etc -iname iptables -exec echo \"I found &#123;&#125;\" \\; I found /etc/bash_completion.d/iptables I found /etc/sysconfig/iptables # find /var/allusers/ -user joe -ok mv &#123;&#125; /tmp/joe/ \\;mv ... /var/allusers/dict.dat &gt; ? y mv ... /var/allusers/five &gt; ? y 想了解更多关于find命令的信息，可以执行命令 man find 使用grep命令在文件中查找 如果希望查找包含特定内容的文件，可以使用grep命令。通过grep命令，可以搜索单个文件，也可以递归搜索整个目录。默认情况下，grep命令是大小写敏感的 12345$ grep desktop /etc/services desktop-dna 2763/tcp # Desktop DNA desktop-dna 2763/udp # Desktop DNA $ grep -i desktop /etc/services sco-dtmgr 617/tcp # SCO Desktop Administration Serversco-dtmgr 617/udp # SCO Desktop Administration Serverairsync 2175/tcp # Microsoft Desktop AirSync Protocol 第一个例子，是在/etc/services文件中查找字符串desktop.第二个例子通过选项-i,在查找时大小写不敏感-v 是查找不包含指定内容的行，-r是在目录中递归查找，-l是列出文件名 而不是包含内容的具体行 1234$ grep -v desktop /etc/services$ grep -rli peerdns /usr/share/doc/ /usr/share/doc/dnsmasq-2.66/setup.html /usr/share/doc/initscripts-9.49.17/sysconfig.txt 以我大谢耳朵结尾吧，主要看气质，哈哈~~","raw":null,"content":null,"categories":[{"name":"linux","slug":"linux","permalink":"http://yemengying.com/categories/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://yemengying.com/tags/linux/"},{"name":"读书笔记","slug":"读书笔记","permalink":"http://yemengying.com/tags/读书笔记/"}]},{"title":"读书笔记-Linux Bible 9th Edition之文件系统","slug":"读书笔记-Linux-Bible-9th-Edition之文件系统","date":"2015-11-26T08:28:15.000Z","updated":"2016-02-23T03:46:42.000Z","comments":true,"path":"2015/11/26/读书笔记-Linux-Bible-9th-Edition之文件系统/","link":"","permalink":"http://yemengying.com/2015/11/26/读书笔记-Linux-Bible-9th-Edition之文件系统/","excerpt":"跟着书，重新梳理一下linux文件系统的有关知识, 最近一天一个接口的节奏真真是极好的,有时间看看书了。😻😻😻 相关博客: Linux Bible 9th Edition之使用shell Linux Bible 9th Edition之玩转文本文件 Linux Bible 9th Edition之进程大法好","keywords":null,"text":"跟着书，重新梳理一下linux文件系统的有关知识, 最近一天一个接口的节奏真真是极好的,有时间看看书了。😻😻😻 相关博客: Linux Bible 9th Edition之使用shell Linux Bible 9th Edition之玩转文本文件 Linux Bible 9th Edition之进程大法好 Linux文件系统结构 在linux中文件组织在一个层级的目录结构中，每个目录可以包含文件和目录，整体看起来就像一个倒过来的树。最上面就是根目录，用”/“符号表示。根目录下面是linux系统中一些常见的目录,比如bin,dev,home,lib等等。下面的图(书上的截图)展示了linux文件系统的层级结构。 基本的一些文件系统命令 命令 作用 cd 进入另一个目录 pwd 打印当前工作目录的路径 mkdir 创建一个目录 chmod 更改文件或目录的权限 ls 列出目录的内容 cd命令cd命令是其中最常用的eg： 12345678# 进入根目录下的usr目录下的share目录 以\"/\"开头，代表在根目录下$ cd /usr/share# 只输入cd 回到home目录$ cd # 进入home目录下的某一目录 \"~\"代表home目录$ cd ~/coffee# 回到上一级目录 \"..\"代表上一级目录$ cd .. 创建目录并查看权限 1234# 创建目录test$ mkdir test# 查看目录权限$ ls -ld test 使用Metacharacters(元字符)和Operators(操作符) 使用metacharacters进行文件匹配 “*”代表任意数量的字符 “?”代表任意一个字符 “[…]”匹配任意一个包含在括号中的字符,也可以用连字符表示一个范围 eg： 123456789101112# 创建5个空文件$ touch apple banana grape grapefruit watermelon$ ls a*apple$ ls g*grape $ ls g???egrape$ ls [abw]*apple banana watermelon$ ls [a-g]*apple banana grape grapefruit 使用metacharacters进行文件重定向 使用管道符号”|”可以将一个命令的标准输出(standard output)作为另一个命令的标准输入(standard input)。对于文件，我们可以用”&lt;”和”&gt;”来将数据从文件中输入或输出。 符号 作用 &lt; 文件的内容输入到命令 &gt; 将一个命令的标准输出输出到文件，如果文件已存在,文件的内容会被覆盖 2&gt; 将错误输出输出到文件 &amp;&gt; 将标准输出和错误输出都输出到文件 &gt;&gt; 将命令的输出到文件中，不覆盖文件原有内容，将输出添加到文件最后 &lt;&lt; 后面要跟着一个单词，之后所有的输入都会当做用户输入，直到重复输入符号后的单词 使用大括号 通过使用大括号”{}”,可以在文件名后扩展一组元素。 eg: 123$ touch &#123;a,b,c&#125;-&#123;1,2,3&#125;$ lsa-1 a-2 a-3 b-1 b-2 b-3 c-1 c-2 c-3 列出文件和目录在linux系统中,ls命令用来列出文件和目录的有关信息，ls命令有许多option。在默认情况下，输入ls，会输出当前目录下所有的非隐藏的文件和目录。如果在命令后在上选项”-l”会输出详细的信息(如下)，其中total代表了目录中的内容占用了多少磁盘空间;第一列第一个字符代表了文件的类型，”-“代表普通文件，”d”代表是目录，”l”代表是一个符号链接,剩下的9个字符代表了文件的权限(下面会讲);第二列展示了文件硬链接数或目录子目录数;第三列显示了文件或目录的拥有者;第四列代表文件拥有者所在的组;第五列是文件的大小;第六列是文件最后的修改时间;最后一列展示了文件或目录的名字;eg： 12$ ls -ltotal 4 -rw-rw-r--. 1 joe joe 0 Dec 18 13:38 apple lrwxrwxrwx. 1 joe joe 5 Dec 18 13:46 pointer_to_apple -&gt; apple -rwxr-xr-x. 1 joe joe 0 Dec 18 13:37 scriptx.sh drwxrwxr-x. 2 joe joe 4096 Dec 18 13:38 Stuff ls命令的其它选项： 选项 作用 -a 展示包含隐藏文件(以.开头)在内的所有文件 -t 按照最近修改时间展示 -F 在展示时，在目录名后加”/“,在可执行文件后加”*”,在符号链接后加”@” -S 展示时按大小排序 -d 只展示包含的目录 -R 递归的列出当前目录下所有的文件和目录 –hide= 不展示指定目录或文件 理解文件权限 在使用Linux系统时，经常会看到”Permission Denied”(权限不足)的提示。权限控制是为了避免用户访问其他用户的私有文件和保护重要的系统文件。在Linux中，每个文件对应一个9bit的权限信息(eg:rwxrwxrwx)。其中前三位代表了文件拥有者的权限，中间三位代表了拥有者所在组的权限，最后三位代表了其他用户的权限。权限由字母代表，”r”代表读权限，”w”代表写权限，”x”代表执行权限，如果某一位不是字母，而是”-“，则代表没有该位所代表的权限。举个两个栗子🌰🌰，”rw-“代表有读写权限，没有执行权限；”r–”代表只有读权限 使用chmod命令更改权限 使用数字 文件的拥有者可以改变文件的权限，每种权限都对应了一个数字，读权限r对应4，写权限w对应2，执行权限x对应1。可以通过设置数值来建立权限。eg: 12345678# 设置权限 rwxrwxrwx# chmod 777 filename# 设置权限 rwxr-xr-x# chomd 755 filename# 设置权限 rw-r--r--# chomd 644 filename# 设置权限 ---------# chmod 000 filename 使用字母 在linux中，还有另一种改变权限的方式。在这种方式中，”+”和”-“分别代表权限的开和关。字母”u”,”g”,”o”和”a”分别代表拥有者,组，其他用户和全部用户。和上一种方式一样”r”,”w”,”x”分别代表读、写和执行权限。eg： 12345678910# 设置权限 将权限rwxrwxrwx改为r-xr-xr-x# chmod a-w filename# 设置权限 将权限rwxrwxrwx改为rwxrwxrw-# chomd o-x filename# 设置权限 将权限rwxrwxrwx改为rwx------# chmod go-rwx filename# 设置权限 将权限---------改为rw-------# chmod u+rw filename# 更改目录下所有文件和目录的权限# chmod -R o-w myapps 使用umask设置默认权限 普通用户创建文件 默认权限是rw-rw-r–，创建目录 默认权限是rwxrwxr-x。root用户创建文件和目录权限分别是rw-r–r–和rwxr-xr-x。这些默认值由umask的值决定，可通过命令umask查看它的值。与chmod效果刚好相反，umask设置的是权限的补码，umask的值有三位分别对应拥有者，同组用户和其他用户的权限。对于文件来说，每一位的最大值是6，因为系统不允许在创建一个文件时就赋予执行权限，需通过chmod设置；对于目录来说每一位的最大值是7。例如umask值002所对应的文件和目录的创建权限是664和775。可通过umask命令改变默认值。eg： 1234# 查看默认值$ umask# 改变默认值$ umask 022 改变文件的拥有者 作为普通用户，是不能更改文件或目录的拥有者的，只有root user(管理员才可以)。eg: 123456# 修改文件的拥有者# chown giraffe filename.text# 同时修改拥有者和组# chown giraffe:coffee filename.txt# 修改目录下的所有目录和文件的拥有者# chown -R giraffe:coffee /mydic 移动 复制 删除文件 移动、复制和删除文件的命令很简单。如果想要改变文件的位置，使用mv命令。如果想要复制文件，使用cp命令。如果想要删除文件，使用rm命令。这些命令可以使用在单一的文件和目录上，也可以递归的使用在许多文件和目录上。 移动文件eg： 1234# 将文件abc移到home目录$ mv abc ~# 将目录mydemo的全部内容移到目录document中$ mv /home/giraffe/mydemo /home/giraffe/document 复制文件eg： 123456# 将文件abc复制到home目录下$ cp abc ~# 将目录bash-completion*下的内容复制到tmp/a下$ cp -r /usr/share/bash-completion* /tmp/a# 将目录bash-completion*下的内容复制到tmp/a下 并且保留权限$ cp -ra /usr/share/bash-completion* /tmp/a 删除文件eg： 12345678910# 删除文件abc$ rm abc# 删除当前目录下所有文件$ rm *# 删除一个空的目录$ rmdir /home/giraffe/empty# 删除目录和他包含的所有内容$ rm -r /home/giraffe/bigdir# 不提示的删除目录和它包含的所有内容$ rm -rf /home/giraffe/bigdir","raw":null,"content":null,"categories":[{"name":"linux","slug":"linux","permalink":"http://yemengying.com/categories/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://yemengying.com/tags/linux/"},{"name":"读书笔记","slug":"读书笔记","permalink":"http://yemengying.com/tags/读书笔记/"}]},{"title":"读书笔记-Linux Bible 9th Edition之使用shell","slug":"读书笔记-Linux-Bible-9th-Edition","date":"2015-11-23T08:23:32.000Z","updated":"2016-02-23T03:47:07.000Z","comments":true,"path":"2015/11/23/读书笔记-Linux-Bible-9th-Edition/","link":"","permalink":"http://yemengying.com/2015/11/23/读书笔记-Linux-Bible-9th-Edition/","excerpt":"其实也不算读书笔记 主要是想整理一下常用的一些linux命令 相关博客: Linux Bible 9th Edition之玩转文本文件 Linux Bible 9th Edition之文件系统 Linux Bible 9th Edition之进程大法好","keywords":null,"text":"其实也不算读书笔记 主要是想整理一下常用的一些linux命令 相关博客: Linux Bible 9th Edition之玩转文本文件 Linux Bible 9th Edition之文件系统 Linux Bible 9th Edition之进程大法好 linux命令的一些语法 $提示符代表普通用户 #提示符代表root用户。 大多数命令都有许多选项 选项通常由单一字符和连字符组成(eg:ls -a),还有选项是由一个单词代表,需在单词前加双连字符(eg:date - -help) 获得当前登录会话的一些信息123$ who $ who am i $ who -uH 查看服务器上的时间12$ date$ date +'%d/%m/%y'(以10/12/14的格式输出) 当前的目录1$ pwd 获得hostname1$ hostname 列出当前目录下的文件和目录12$ ls$ ls -l(列出详细信息) -a(列出包括.开头的隐含文件在内的所有文件) -t(按时间排序) 查看uid gid1$ id LINUX如何定位命令 可通过echo $PATH命令查看PATH环境变量的值，如果命令存放的目录包含在PATH中，可直接输入命令运行。如果不包含则需给出命令的位置(eg:绝对位置:/home/chris/scriptx.sh,相对位置:./scriptx.sh) shell检查输入命令的顺序：1.Aliases(别名) 2.Reserved word(保留的关键字) 3.Function 4.Build-in command(eg:cd/echo/exit/type..) 5.Filesystem 1234#查看一个命令的位置$ type bash#打印PATH环境变量的值$ echo $PATH 在文件系统中查找1$ locate ymy 查看历史输入的命令,修改命令 可以用history命令查看之前输入过的所有命令,之后可以通过!+行号 运行指定一行的命令。向上箭头(↑)可查看最近一条命令,下面是修改命令的一些快捷按键。 快捷键 作用 ctrl+A 将光标定位到命令的最前面 ctrl+E 将光标定位到命令的最后面 ctrl+L 清空屏幕，将命令置为最上面 ctrl+F或 → 将光标后移 ctrl+B或 ← 将光标前移 alt+F 将光标后移一个单词 alt+B 将光标前移一个单词 ctrl+D 删除当前字符 backspace 删除前一个字符 ctrl+T 将当前字符和前一个字符对换 alt+T 将当前单词和前一个单词对换 alt+U 将当前单词变成大写 alt+L 将当前单词变成小写 ctrl+K 剪切从光标位置到最后 ctrl+U 剪切从光标位置到最前 ctrl+W 剪切前一个单词 alt+D 剪切后一个单词 ctrl+Y 粘贴最近复制的内容 alt+Y 粘贴最前复制的内容 tab 补全命令 连接和扩展命令 管道符号 “|”将前一个命令的输出作为下一个命令的输入eg: 1$ cat /etc/passwd | sort |less 命令分隔符 “;”在一行语句中 顺次执行各个命令eg: 12#可获得troff命令的执行时间$ date; troff -me verylargedocument|lpr ; date 后台进程符 “&amp;”如果不希望shell一直被一个命令占用着，可以使用”&amp;”让命令在后台运行eg: 1$ troff -me verylargedocument | lpr &amp; 使用数学表达式/命令的结果 “$[]”/“$()”可以在一个命令中使用数学表达式或另一个命令的结果eg: 12$ echo \"I am $[2015 - 1993] years old\"$ echo \"there are $(ls | wc -w) files in this directory\" 变量调用符号 “$”eg: 1$ echo $USER 创建和使用别名使用alias命令，可以给任何的命令及选项取一个别名eg: 123456#为命令pwd取别名ymy$ alias ymy='pwd'#查看所有的别名$ alias#删除别名$ unalias ymy 退出shell1$ exit","raw":null,"content":null,"categories":[{"name":"linux","slug":"linux","permalink":"http://yemengying.com/categories/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://yemengying.com/tags/linux/"},{"name":"读书笔记","slug":"读书笔记","permalink":"http://yemengying.com/tags/读书笔记/"}]},{"title":"EsGiraffe-利用注解和反射拼接Elasticsearch查询语句","slug":"EsGiraffe-利用注解和反射拼接Elasticsearch查询语句","date":"2015-11-19T05:56:50.000Z","updated":"2016-04-23T02:01:58.000Z","comments":true,"path":"2015/11/19/EsGiraffe-利用注解和反射拼接Elasticsearch查询语句/","link":"","permalink":"http://yemengying.com/2015/11/19/EsGiraffe-利用注解和反射拼接Elasticsearch查询语句/","excerpt":"EsGiraffe 封闭开发结束，终于有时间可以整理一下了。EsGiraffe是一个利用注解和反射开发一套工具类，用来生成elastisearch的查询语句。为什么要叫Giraffe呢？一是因为我喜欢长颈鹿，二是希望可以通过工具类把像长颈鹿脖子一样长的代码简化一下，三是希望这个工具类可以像桥梁一样连接java和elaticsearch。实在编不下去了，其实就是因为喜欢长颈鹿。目前只适用于简单的查询，不过会在工作学习中慢慢完善的。由于目前在工作中用到最多的就是Bool查询，所以目前生成的查询语句最外层就是bool查询，生成的大致的样子如下: &quot;query&quot;: { &quot;bool&quot;: { &quot;must&quot;: [ ... ], &quot;must_not&quot;: [ ... ], &quot;should&quot;: [ ... ] } } git地址： loadStyle(\"/hexo-github/style.css\"); loadStyle(\"/hexo-github/octicons/octicons.css\"); new Badge(\"#badge-container-giraffe0813-EsGiraffe-6afdc51\", \"giraffe0813\", \"EsGiraffe\", \"6afdc51\", false);","keywords":null,"text":"EsGiraffe 封闭开发结束，终于有时间可以整理一下了。EsGiraffe是一个利用注解和反射开发一套工具类，用来生成elastisearch的查询语句。为什么要叫Giraffe呢？一是因为我喜欢长颈鹿，二是希望可以通过工具类把像长颈鹿脖子一样长的代码简化一下，三是希望这个工具类可以像桥梁一样连接java和elaticsearch。实在编不下去了，其实就是因为喜欢长颈鹿。目前只适用于简单的查询，不过会在工作学习中慢慢完善的。由于目前在工作中用到最多的就是Bool查询，所以目前生成的查询语句最外层就是bool查询，生成的大致的样子如下: &quot;query&quot;: { &quot;bool&quot;: { &quot;must&quot;: [ ... ], &quot;must_not&quot;: [ ... ], &quot;should&quot;: [ ... ] } } git地址： loadStyle(\"/hexo-github/style.css\"); loadStyle(\"/hexo-github/octicons/octicons.css\"); new Badge(\"#badge-container-giraffe0813-EsGiraffe-6afdc51\", \"giraffe0813\", \"EsGiraffe\", \"6afdc51\", false); 常见的工作需求在我工作比较常见的搜索需求就是对外提供搜索的接口。会按照搜索引擎中的字段定义一个对应的model，然后这些字段的值如果为Null，就代表调用方不想对这个字段进行查询，如果不为Null代表需要对这个字段进行查询。而且还会提前在API文档中定义好查询的类型是must、must_not还是should 未使用工具类的代码Demo假设有一个和订单有关的索引，需要对订单的一系列属性进行查询 其中userName和orderMode是should查询 其余都是must查询model： 1234567891011121314151617181920212223public class OrderModel &#123; private String userName; private Integer restaurantId; private Integer orderMode; private String userPhone; private Integer comeFrom; private String restaurantName; private String createdAtBegin; private String createdAtEnd; private Integer offset = 0; private Integer limit = 10; //省略getter和setter &#125; 查询方法： 123456789101112131415161718192021222324252627282930313233343536373839404142public SearchService implements ISearchService&#123; public String searchOrder(SearchOrderModel search) throws IllegalAccessException&#123; BoolQueryBuilder baseQuery = QueryBuilders.boolQuery(); if(search.getUserName() != null)&#123; baseQuery.should(QueryBuilders.termQuery(\"user_name\", search.getUserName())); &#125; if(search.getRestaurantId() != null)&#123; baseQuery.must(QueryBuilders.termQuery(\"restaurant_id\", search.getRestaurantId())); &#125; if(search.getOrderMode() != null)&#123; baseQuery.should(QueryBuilders.termQuery(\"order_mode\", search.getOrderMode())); &#125; if(search.getUserPhone() != null)&#123; baseQuery.must(QueryBuilders.termQuery(\"user_phone\", search.getUserPhone())); &#125; if(search.getComeFrom() != null)&#123; baseQuery.must(QueryBuilders.termQuery(\"come_from\", search.getComeFrom())); &#125; if(search.getRestaurantName() != null)&#123; baseQuery.must(QueryBuilders.queryStringQuery(search.getRestaurantName()).defaultField(\"restaurant_name\")); &#125; if(search.getCreatedAtBegin() != null)&#123; baseQuery.must(QueryBuilders.rangeQuery(\"created_at\").gte(search.getCreatedAtBegin())); &#125; if(search.getCreatedAtEnd() != null)&#123; baseQuery.must(QueryBuilders.rangeQuery(\"created_at\").lte(search.getCreatedAtBegin())); &#125; log.info(\"查询语句:&#123;&#125;\",baseQuery.toString()); SearchResponse response = client.prepareSearch(\"index1\") .setTypes(\"type1\") .setSearchType(SearchType.DFS_QUERY_THEN_FETCH) .setQuery(baseQuery) .setFrom(search.getOffset()).setSize(search.getLimit()).setExplain(true) .execute() .actionGet(); return response.toString(); &#125;&#125; 下面是针对餐厅名称，用户名和来源同时查询时，打印出来的拼接的查询语句: 123456789101112131415161718&#123; \"bool\" : &#123; \"must\" : [ &#123; \"term\" : &#123; \"come_from\" : 1 &#125; &#125;, &#123; \"query_string\" : &#123; \"query\" : \"测试餐厅\", \"default_field\" : \"restaurant_name\" &#125; &#125; ], \"should\" : &#123; \"term\" : &#123; \"user_name\" : \"123123123\" &#125; &#125; &#125; &#125; 可是上面只是缩减版的订单model，一个订单的属性有20多个 所以每个属性都判断是否为null，代码就太不漂亮了,而且可读性差，不易维护，所以就想通过注解和反射来精简代码。 EsGiraffe的主要内容EsGiraffe主要是自定义了一些注解，将一些诸如model属性对应的搜索引擎的字段，查询的类型，要查询的index名，要查询的document名用注解标注在model类上，然后在工具类中利用反射获取注解的值 拼接查询语句。下面是几个比较重要的注解: Index注解 DocumentType注解 只能在类上使用 Index代表要在哪个索引中查询， Document代表要查询的文档 可以指定多个索引或文档用”,”分割 例子: 1234@Index(\"index\")@DocumentType(\"document1\")public class model&#123;&#125; EsField注解 在类的属性上使用 值为该属性对应的索引字段名 如果value为空，那么对应的索引名就是该属性名。这个注解主要是考虑到在Java习惯驼峰式的命名，而搜索引擎中往往是下划线，所以需要一个注解将他们对应起来。 例子: 1234567@Index(\"index\")@DocumentType(\"document1\")public class model&#123; @EsField(\"come_from\") private Integer comeFrom;&#125; 不过，这两个注解只适用于在查询前就确定要查询的索引和文档时使用。如果要根据查询的内容才能确定要查询的文档，目前没有想到什么好的解决办法，这种情况只能不用Index和DocumentType注解了。比如做活动查询时，活动索引到搜索引擎中是按照活动所属的城市存储到不同的文档，举个栗子🌰，如果活动1的城市id是1,那么活动1就存在在文档activity_1,如果活动2的城市id是3，那么活动2就存在在文档activity_3中，这种情况就不能靠通过注解的方式获得查询的文档了。 Bool注解 最重要的注解，里面包含5个元素value,type,escape,fuzziness,prefix。其中value是MatchType(枚举类)类型，代表了该Bool查询是MUST，MUST_NOT还是SHOULD，默认是MUST。type的值是EsSearchType(枚举类)类型，代表对该字段采用什么类型的查询。默认值是TERMS，支持的其他类型还有TERM,RANGE_FROM, RANGE_TO, RANGE_GT,RANGE_LT, RANGE_GTE, RANGE_LTE, FUZZY, SHOULD_TERM, QUERY_STRING, MATCH。escape是布尔类型的，代表是否需要进行特殊字符(eg: !$()等)的转换，默认值是false。fuzziness和prefix是在新版本中针对type=EsSearchType.FUZZY做的扩展而新增的元素。分别代表Fuzzy Query中的fuzziness和prefix_length,这两个参数的意思可以到官方文档上看，fuzziness的值只能为[0,1,2],否则会报错“org.elasticsearch.ElasticsearchIllegalArgumentException: Valid edit distances are [0, 1, 2]”，不要问我为什么知道。要注意的是这两个元素只有在type=EsSearchType.FUZZY时才有效 例子： 123456789101112@Index(\"index\")@DocumentType(\"document1\")public class model&#123; @EsField(\"come_from\") @Bool(type = EsSearchType.TERM) private Integer comeFrom; @EsField(\"created_at\") @Bool(type = EsSearchType.RANGE_GTE) private String createdAtBegin;&#125; 上面的注解代表的查询语句是 1234567891011121314151617&#123; \"bool\" : &#123; \"must\" : [ &#123; \"term\" : &#123; \"come_from\" : 1 &#125; &#125;, &#123; \"range\" : &#123; \"created_at\" : &#123; \"from\" : \"2015-02-03\", \"to\" : null, \"include_lower\" : true, \"include_upper\" : true &#125; &#125; &#125; ] &#125; &#125; From,Size,Sort注解 这三个注解也是用到类的属性上的，如果一个属性上标有From注解，代表这个字段的值是查询分页的起始位置；如果一个属性上标有Size注解，代表这个字段的值是分页的长度；如果一个属性上标有Sort注解，代表查询结果按该字段排序，Sort的值有SortType.ASC和SortType.DESC两种。 ElasticBaseSearch中两个工具方法 getIndexAndType和getQueryBuilder 已经在类和属性添加了注解，那么就需要写两个方法分别通过反射获取类和属性上的值 来拼接对应的查询语句。其中getQueryBuilder是根据属性上的注解拼装查询语句并返回一个QueryBuilder对象，getIndexAndType是根据注解获得要查询的索引，文档等信息，并返回一个SearchRequestBuilder对象。 使用EsGiraffe简化代码 下面是使用EsGiraffe简化后的代码 查询model类 12345678910111213141516171819202122232425262728293031323334353637383940414243@Index(\"index1\")@DocumentType(\"type1\")public class OrderModel &#123; @EsField(\"user_name\") @Bool(type = EsSearchType.QUERY_STRING, value = MatchType.SHOULD, escape=true) private String userName; @EsField(\"restaurant_id\") @Bool(type = EsSearchType.TERM) private Integer restaurantId; @EsField(\"order_mode\") @Bool(type = EsSearchType.TERM) private Integer orderMode; @EsField(\"usr_phone\") @Bool(type = EsSearchType.TERM) private String userPhone; @EsField(\"come_from\") @Bool(type = EsSearchType.TERM) private Integer comeFrom; @EsField(\"restaurant_name\") @Bool(type = EsSearchType.QUERY_STRING,escape=true) private String restaurantName; @EsField(\"created_at\") @Bool(type = EsSearchType.RANGE_GTE) private String createdAtBegin; @EsField(\"created_at\") @Bool(type = EsSearchType.RANGE_LTE) private String createdAtEnd; @From private Integer offset = 0; @Size private Integer limit = 10; //省略getter和setter &#125; 接口类，也无需写大量的业务逻辑，只需要调用两个工具方法即可 12345678910111213141516public String searchOrder(SearchOrderModel search) throws IllegalAccessException &#123; log.info(\"查询参数:&#123;&#125;\", search.toString()); QueryBuilder baseQuery = ElasticBaseSearch.getInstance().getQueryBuilder(search); if(baseQuery != null)&#123; log.info(baseQuery.toString()); SearchResponse response = ElasticBaseSearch.getInstance().getIndexAndType(client, search).setQuery(baseQuery).execute().actionGet(); log.info(response.toString()); return response.toString(); &#125; return \"\";&#125; 使用了EsGiraffe之后，大大简化了查询接口的代码，无需挨个属性判断是否为null。而且在model类上使用注解，使得程序变得更加可读，每个属性对应搜索引擎中哪个字段，采用哪种查询方式一目了然。下面是使用EsGiraffe之后，对餐厅名称，用户名和来源查询时打印的查询语句，和不用注解生成的是一样的。 123456789101112131415161718&#123; \"bool\" : &#123; \"must\" : [ &#123; \"term\" : &#123; \"come_from\" : 1 &#125; &#125;, &#123; \"query_string\" : &#123; \"query\" : \"测试餐厅\", \"default_field\" : \"restaurant_name\" &#125; &#125; ], \"should\" : &#123; \"term\" : &#123; \"user_name\" : \"123123123\" &#125; &#125; &#125; &#125;","raw":null,"content":null,"categories":[{"name":"elasticsearch","slug":"elasticsearch","permalink":"http://yemengying.com/categories/elasticsearch/"}],"tags":[{"name":"elasticsearch","slug":"elasticsearch","permalink":"http://yemengying.com/tags/elasticsearch/"},{"name":"java","slug":"java","permalink":"http://yemengying.com/tags/java/"},{"name":"annotation","slug":"annotation","permalink":"http://yemengying.com/tags/annotation/"},{"name":"reflect","slug":"reflect","permalink":"http://yemengying.com/tags/reflect/"}]},{"title":"读书笔记---深入理解Java虚拟机1","slug":"读书笔记-深入理解Java虚拟机1","date":"2015-11-12T09:23:23.000Z","updated":"2016-02-02T06:25:01.000Z","comments":true,"path":"2015/11/12/读书笔记-深入理解Java虚拟机1/","link":"","permalink":"http://yemengying.com/2015/11/12/读书笔记-深入理解Java虚拟机1/","excerpt":"","keywords":null,"text":"最近看书总是看不进去，所以。。。决定边看边画画图，做个总结。下面是深入理解Java虚拟机这本书的第二，三章的总结。","raw":null,"content":null,"categories":[{"name":"java","slug":"java","permalink":"http://yemengying.com/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"http://yemengying.com/tags/java/"},{"name":"读书笔记","slug":"读书笔记","permalink":"http://yemengying.com/tags/读书笔记/"}]},{"title":"【译】如何在java中使用ConcurrentHashMap","slug":"【译】如何在java中使用ConcurrentHashMap","date":"2015-11-06T05:20:37.000Z","updated":"2016-04-22T13:43:07.000Z","comments":true,"path":"2015/11/06/【译】如何在java中使用ConcurrentHashMap/","link":"","permalink":"http://yemengying.com/2015/11/06/【译】如何在java中使用ConcurrentHashMap/","excerpt":"原文来自一个java大牛的技术博客 地址http://javarevisited.blogspot.com/2013/02/concurrenthashmap-in-java-example-tutorial-working.html 博客讲解了如何在java中使用ConcurrentHashMap。马上要封闭开发10天，连上15天班，真酸爽。下面是原文的翻译：","keywords":null,"text":"原文来自一个java大牛的技术博客 地址http://javarevisited.blogspot.com/2013/02/concurrenthashmap-in-java-example-tutorial-working.html 博客讲解了如何在java中使用ConcurrentHashMap。马上要封闭开发10天，连上15天班，真酸爽。下面是原文的翻译： ConcurrentHashMap(简称CHM)是在Java 1.5作为Hashtable的替代选择新引入的，是concurrent包的重要成员。在Java 1.5之前，如果想要实现一个可以在多线程和并发的程序中安全使用的Map,只能在HashTable和synchronized Map中选择，因为HashMap并不是线程安全的。但再引入了CHM之后，我们有了更好的选择。CHM不但是线程安全的，而且比HashTable和synchronizedMap的性能要好。相对于HashTable和synchronizedMap锁住了整个Map，CHM只锁住部分Map。CHM允许并发的读操作，同时通过同步锁在写操作时保持数据完整性。我们已经在Top 5 Java Concurrent Collections from JDK 5 and 6中学习了CHM的基础知识，在这篇博客中我将介绍以下几点： CHM在Java中如何实现的 什么情况下应该使用CHM 在Java中使用CHM的例子 CHM的一些重要特性 Java中ConcurrentHashMap的实现CHM引入了分割，并提供了HashTable支持的所有的功能。在CHM中，支持多线程对Map做读操作，并且不需要任何的blocking。这得益于CHM将Map分割成了不同的部分，在执行更新操作时只锁住一部分。根据默认的并发级别(concurrency level)，Map被分割成16个部分，并且由不同的锁控制。这意味着，同时最多可以有16个写线程操作Map。试想一下，由只能一个线程进入变成同时可由16个写线程同时进入(读线程几乎不受限制)，性能的提升是显而易见的。但由于一些更新操作，如put(),remove(),putAll(),clear()只锁住操作的部分，所以在检索操作不能保证返回的是最新的结果。 另一个重要点是在迭代遍历CHM时，keySet返回的iterator是弱一致和fail-safe的，可能不会返回某些最近的改变，并且在遍历过程中，如果已经遍历的数组上的内容变化了，不会抛出ConcurrentModificationExceptoin的异常。 CHM默认的并发级别是16，但可以在创建CHM时通过构造函数改变。毫无疑问，并发级别代表着并发执行更新操作的数目，所以如果只有很少的线程会更新Map，那么建议设置一个低的并发级别。另外，CHM还使用了ReentrantLock来对segments加锁。 Java中ConcurrentHashMap putifAbsent方法的例子很多时候我们希望在元素不存在时插入元素，我们一般会像下面那样写代码 1234567synchronized(map)&#123; if (map.get(key) == null)&#123; return map.put(key, value); &#125; else&#123; return map.get(key); &#125;&#125; 上面这段代码在HashMap和HashTable中是好用的，但在CHM中是有出错的风险的。这是因为CHM在put操作时并没有对整个Map加锁，所以一个线程正在put(k,v)的时候，另一个线程调用get(k)会得到null，这就会造成一个线程put的值会被另一个线程put的值所覆盖。当然，你可以将代码封装到synchronized代码块中，这样虽然线程安全了，但会使你的代码变成了单线程。CHM提供的putIfAbsent(key,value)方法原子性的实现了同样的功能，同时避免了上面的线程竞争的风险。 什么时候使用ConcurrentHashMapCHM适用于读者数量超过写者时，当写者数量大于等于读者时，CHM的性能是低于Hashtable和synchronized Map的。这是因为当锁住了整个Map时，读操作要等待对同一部分执行写操作的线程结束。CHM适用于做cache,在程序启动时初始化，之后可以被多个请求线程访问。正如Javadoc说明的那样，CHM是HashTable一个很好的替代，但要记住，CHM的比HashTable的同步性稍弱。 总结现在我们知道了什么是ConcurrentHashMap和什么时候该用ConcurrentHashMap，下面我们来复习一下CHM的一些关键点。 CHM允许并发的读和线程安全的更新操作 在执行写操作时，CHM只锁住部分的Map 并发的更新是通过内部根据并发级别将Map分割成小部分实现的 高的并发级别会造成时间和空间的浪费，低的并发级别在写线程多时会引起线程间的竞争 CHM的所有操作都是线程安全 CHM返回的迭代器是弱一致性，fail-safe并且不会抛出ConcurrentModificationException异常 CHM不允许null的键值 可以使用CHM代替HashTable，但要记住CHM不会锁住整个Map 以上就是Java中CHM的实现和使用场景","raw":null,"content":null,"categories":[{"name":"java","slug":"java","permalink":"http://yemengying.com/categories/java/"},{"name":"hashmap","slug":"java/hashmap","permalink":"http://yemengying.com/categories/java/hashmap/"}],"tags":[{"name":"java","slug":"java","permalink":"http://yemengying.com/tags/java/"},{"name":"翻译","slug":"翻译","permalink":"http://yemengying.com/tags/翻译/"}]},{"title":"【译】Java8中的扩展(default/extension)方法","slug":"Java-8中的扩展-Default-Defender-Extension-方法","date":"2015-11-01T14:11:06.000Z","updated":"2016-04-22T13:45:06.000Z","comments":true,"path":"2015/11/01/Java-8中的扩展-Default-Defender-Extension-方法/","link":"","permalink":"http://yemengying.com/2015/11/01/Java-8中的扩展-Default-Defender-Extension-方法/","excerpt":"原文来自一个java大牛的技术博客 地址http://javarevisited.blogspot.hk/2014/07/default-defender-or-extension-method-of-Java8-example-tutorial.html#uds-search-results 博客讲解了Java 8中新引入的可以在接口中定义扩展方法。下面是原文的翻译。 Java 8允许开发者使用default和static两个关键字在接口中加入非抽象的方法。带有default关键字的方法在Java中也被称作defender方法或defaul方法。在Java 8之前，想要改变一个已经发布的接口几乎是不可能的，任何改动(例如增加一个新的方法)都会影响该接口现有的实现类。这也是为什么在Java 8想要改变内部iterator的实现，使用forEach()方法时面临了一个巨大的挑战，因为这会破坏了现有的Iterable接口的实现类。毫无疑问，向后兼容是Java工程师最优先考虑的事，所以要破坏现有的实现类是不可行的。因此，他们提出了一个解决办法，引入default方法。这是一个绝妙的想法，因为现在你可以用扩展现有的接口。JDK本身也使用了许多default方法,java.util.Map接口扩展了许多default方法，例如replaceAll(),putIfAbsent(Key k,Value v)….。另外，由于default方法可以扩展现有的接口也被称作extension方法。一个接口中的default方法是数量不受限制的。我相信，在这次改变之后，将不再需要抽象类来提供骨架实现(skeletal implementation),例如List接口有AbstractList，Collection接口有AbstractCollection，Set接口有AbstractSet，Map接口有AbstractMap。我们可以通过在接口中定义default方法来替代创建一个新的抽象类。相似的，static方法的引入也使得接口的工具类变得冗余。例如，Collection接口的Collections类，Path接口的Paths类，因为你可以直接在接口中定义静态工具方法。如果你想了解更多关于Java 8的新特性，我建议阅读Cay S. Horstmann写的Java SE 8 Really Impatient。这是我最喜欢的关于Java 8的书之一，它详细的介绍了Java7与Java 8不同的特性。","keywords":null,"text":"原文来自一个java大牛的技术博客 地址http://javarevisited.blogspot.hk/2014/07/default-defender-or-extension-method-of-Java8-example-tutorial.html#uds-search-results 博客讲解了Java 8中新引入的可以在接口中定义扩展方法。下面是原文的翻译。 Java 8允许开发者使用default和static两个关键字在接口中加入非抽象的方法。带有default关键字的方法在Java中也被称作defender方法或defaul方法。在Java 8之前，想要改变一个已经发布的接口几乎是不可能的，任何改动(例如增加一个新的方法)都会影响该接口现有的实现类。这也是为什么在Java 8想要改变内部iterator的实现，使用forEach()方法时面临了一个巨大的挑战，因为这会破坏了现有的Iterable接口的实现类。毫无疑问，向后兼容是Java工程师最优先考虑的事，所以要破坏现有的实现类是不可行的。因此，他们提出了一个解决办法，引入default方法。这是一个绝妙的想法，因为现在你可以用扩展现有的接口。JDK本身也使用了许多default方法,java.util.Map接口扩展了许多default方法，例如replaceAll(),putIfAbsent(Key k,Value v)….。另外，由于default方法可以扩展现有的接口也被称作extension方法。一个接口中的default方法是数量不受限制的。我相信，在这次改变之后，将不再需要抽象类来提供骨架实现(skeletal implementation),例如List接口有AbstractList，Collection接口有AbstractCollection，Set接口有AbstractSet，Map接口有AbstractMap。我们可以通过在接口中定义default方法来替代创建一个新的抽象类。相似的，static方法的引入也使得接口的工具类变得冗余。例如，Collection接口的Collections类，Path接口的Paths类，因为你可以直接在接口中定义静态工具方法。如果你想了解更多关于Java 8的新特性，我建议阅读Cay S. Horstmann写的Java SE 8 Really Impatient。这是我最喜欢的关于Java 8的书之一，它详细的介绍了Java7与Java 8不同的特性。 Default方法的例子Java 8让我们可以通过default关键字为接口添加非抽象的方法。这一特性也被称作Extension(扩展)方法。下面是第一个例子： 12345678interface Multiplication&#123; int multiply(int a, int b); default int square(int a)&#123; return multiply(a, a); &#125; &#125; 除了抽象方法multiply()之外，接口Multiplication还包含一个default方法square()。任何实现Multiplication接口的类只需实现抽象方法multiply，default方法square()可以直接使用。 12345678910Multiplication product = new Multiplication()&#123; @Override public int multiply(int x, int y)&#123; return x*y; &#125;&#125;; int square = product.square(2); int multiplication = product.multiply(2, 3); product是个匿名类。这段代码有点啰嗦了，用了6行实现一个简单地乘法的功能。我们可以利用lambda表达式来简化一下代码，lambda表达式也是Java 8中新引入的。因为我们的接口只包含一个抽象方法，而且lambda表达式也是SAM(Single Abstract method单一抽象方法)类型的。我们可以用lambda表达式来替代匿名类将代码简化成下面的样子。 123Multiplication lambda = (x, y) -&gt; x*y; int product = lambda.multiply(3, 4); int square = lambda.square(4); 以上就是在接口中使用default方法的例子。现在，你可以毫无顾虑的在旧的接口中扩展新的方法，只要这些方法是default或static的就不用担心会破坏接口的实现类。 123456789101112131415161718192021222324252627282930313233343536373839404142/**Java Program to demonstrate use of default method in Java 8. * You can define non-abstract method by using default keyword, and more * than one default method is permitted, which allows you to ship default skeletal * implementation on interface itself. * @author Javin Paul */ public class Java8DefaultMethodDemo&#123; public static void main(String args[]) &#123; // Implementing interface using Anonymous class Multiplication product = new Multiplication()&#123; @Override public int multiply(int x, int y)&#123; return x*y; &#125; &#125;; int squareOfTwo = product.square(2); int cubeOfTwo = product.cube(2); System.out.println(\"Square of Two : \" + squareOfTwo); System.out.println(\"Cube of Two : \" + cubeOfTwo); // Since Multiplication has only one abstract method, it can // also be implemented using lambda expression in Java 8 Multiplication lambda = (x, y) -&gt; x*y; int squareOfThree = lambda.square(3); int cubeOfThree = lambda.cube(3); System.out.println(\"Square of Three : \" + squareOfThree); System.out.println(\"Cube of Three : \" + cubeOfThree); &#125; &#125; interface Multiplication&#123; int multiply(int a, int b); default int square(int a)&#123; return multiply(a, a); &#125; default int cube(int a)&#123; return multiply(multiply(a, a), a); &#125; &#125; Output : Square of Two : 4 Cube of Two : 8 Square of Three : 9 Cube of Three : 27 这是个很好的关于如何使用default方法在接口中方便的添加方法的例子。也展示了如何避免一个额外的帮助类，比如Collections类。它仅仅提供了一些用于Collection的工具方法，而现在我们可以直接在Collection中定义这些方法。在上面的例子中，我们有一个包含一个抽象方法multiply(a,b)的接口Multiplication，接口还包括两个依赖于multiply(a,b)方法的非抽象方法square(a)和cube(b)。接口的实现类只需要实现multiply(a,b)方法，就可以直接使用square(a)和cube(b)方法了。 default方法的关键点现在让我们来复习我们刚刚学到了什么，记一下关于default方法的关键点。 在Java8中你可以在接口中添加default方法 default方法的出现使得接口和抽象类的不同变得模糊。所以，当在面试中被问到这个问题，别忘了提一下，以前只能通过抽象类实现的事情，现在也可以通过default方法实现了。 default并不是一个新的关键字，在JDK1.1中就是保留关键字 接口中default方法的数量没有限制 如果接口C继承了接口A和B，如果A和B中拥有一样的default方法，编译器在编译过程中会报错。为了避免歧义，这在Java 8中是不允许的。所以当default方法有冲突时，是不可以多继承的 在JDK1.8中有许多关于default方法的例子，比如forEach方法。也可以查看java.util.Map中新添的putIfAbsent方法，在JDK1.8之前，我们只能ConcurrentMap来使用它。 以上就是default方法。不得不说，这是一个巨大的突破，使我们可以更好更方便的使用接口。了解CurrentMap的putIfAbsent方法可以帮助我们更好的记住default方法。在JDK1.7中，putIfAbsent方法并不存在于Map接口中，所以为了使用putIfAbsent方法，必须将Map接口指向的ConcurrentMap对象强制转换成ConcurrentMap。但Java 8引入扩展方法之后，Map接口中也有了putIfAbsent方法。想了解更多的关于Java8的新特性，可以阅读Manning&#39;s Java 8 in Action","raw":null,"content":null,"categories":[{"name":"java","slug":"java","permalink":"http://yemengying.com/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"http://yemengying.com/tags/java/"},{"name":"interface","slug":"interface","permalink":"http://yemengying.com/tags/interface/"},{"name":"翻译","slug":"翻译","permalink":"http://yemengying.com/tags/翻译/"}]},{"title":"【译】以生产者消费者为例阐述如何使用wait，notify和notifyAll","slug":"译-以生产者消费者为例阐述如何使用wait，notify和notifyAll","date":"2015-10-29T06:34:55.000Z","updated":"2016-02-03T09:59:21.000Z","comments":true,"path":"2015/10/29/译-以生产者消费者为例阐述如何使用wait，notify和notifyAll/","link":"","permalink":"http://yemengying.com/2015/10/29/译-以生产者消费者为例阐述如何使用wait，notify和notifyAll/","excerpt":"原文来自一个java大牛的技术博客 地址http://javarevisited.blogspot.com/2015/07/how-to-use-wait-notify-and-notifyall-in.html 博客以生产者和消费者为例 讲解了如何使用wait,notify,notifyAll进行多个线程之间的通信。下面是原文的翻译。 在Java中可以利用use,notify,notifyAll来完成线程之间的通信。举个例子，假设你的程序中有两个线程(eg:Producer(生产者)和Consumer(消费者))，Producer要和Consumer通信，通知Consumer队列中有元素了可以开始消费。相似的，Consumer也需要通知Producer队列中有空闲可以插入元素了。一个线程可以可以在一定条件下调用wait方法暂停什么都不做。比如，在Producer和consumer的问题中，当队列满了时Producer需要调用wait，当队列为空时Consumer需要调用wait方法。如果一些线程在等待某些条件变为真，可以在条件改变时使用notify和notifyAll通知他们并唤醒他们。Notify方法和NotifyAll方法都可以发送通知，不同的是，notify只能向等待的线程中的一个发送通知，不保证接受到通知的是哪个线程，而NotifyAll会向所有线程发送通知。所以如果只有一个线程等待对象锁，notify和notifyAll都会通知到它。在这个java多线程的教程中，将利用生产者，消费者的例子讲述在Java中如何使用wait，notify和notifyAll实现线程内部通信。另外，如果大家对掌握多线程和并发很感兴趣，强烈建议大家阅读Brian Goetz写的Java Concurrency in Practice。如果没看过这本书，你的Java多线程之旅是不完整的🙀。","keywords":null,"text":"原文来自一个java大牛的技术博客 地址http://javarevisited.blogspot.com/2015/07/how-to-use-wait-notify-and-notifyall-in.html 博客以生产者和消费者为例 讲解了如何使用wait,notify,notifyAll进行多个线程之间的通信。下面是原文的翻译。 在Java中可以利用use,notify,notifyAll来完成线程之间的通信。举个例子，假设你的程序中有两个线程(eg:Producer(生产者)和Consumer(消费者))，Producer要和Consumer通信，通知Consumer队列中有元素了可以开始消费。相似的，Consumer也需要通知Producer队列中有空闲可以插入元素了。一个线程可以可以在一定条件下调用wait方法暂停什么都不做。比如，在Producer和consumer的问题中，当队列满了时Producer需要调用wait，当队列为空时Consumer需要调用wait方法。如果一些线程在等待某些条件变为真，可以在条件改变时使用notify和notifyAll通知他们并唤醒他们。Notify方法和NotifyAll方法都可以发送通知，不同的是，notify只能向等待的线程中的一个发送通知，不保证接受到通知的是哪个线程，而NotifyAll会向所有线程发送通知。所以如果只有一个线程等待对象锁，notify和notifyAll都会通知到它。在这个java多线程的教程中，将利用生产者，消费者的例子讲述在Java中如何使用wait，notify和notifyAll实现线程内部通信。另外，如果大家对掌握多线程和并发很感兴趣，强烈建议大家阅读Brian Goetz写的Java Concurrency in Practice。如果没看过这本书，你的Java多线程之旅是不完整的🙀。 在代码中展示如何使用wait和notify尽管wait和notify是相当基础的概念，并且他们定义在Object类中，但要想在代码中使用他们并非易事。你可以在面试中让面试者通过手写代码解决Producer者和Consumer者问题来验证，我相信大多数人都会犯在错误的地方同步，没有在正确的对象上调用wait之类的错。讲真，这些常常会困惑许多程序员。第一个困惑点来自怎样调用wait方法，因为wait方法并不是定义在Thread类中，所以不能简单的Thread.wait()。而许多Java开发者习惯于Thread.sleep(),所以常常错误的想用同样的方式调用wait。实际上，wait()方法需要在一个被两个线程共享的对象上调用，例如在Producer者和消费Consumer的问题中，两个线程共享对象是一个队列。第二个困惑点来自wait方法应该在同步块还是同步方法中调用？如果使用同步块，那么哪个对象应该放到同步块中？这个对象和你想要获得锁的对象应该是同一个。在我们的例子中，这个对象就是两个线程共享的队列。 在循环中使用wait和notify，而不是If代码块中在你已经了解需要在一个共享的对象上调用wait方法后，接下来就是学会避免许多java开发者犯的错—在If代码块中调用wait而不是while循环中。因为需要在一定的条件下调用wait，比如Producer线程要在队列满了的情况下调用wait，所以第一反应都是使用If语句。但是，在If代码块中调用wait会产生bug，因为线程存在一定的可能在等待条件没有改变的情况下假唤醒(spurious wake up)。所以如果没有使用循环在线程唤醒后检查等待条件，可能会造成尝试在已经满了的队列中插入元素或者在空了的队列中取元素。这就是为什么我们要在while循环中调用wait而不是if。 12345678 // The standard idiom for calling the wait method in Java synchronized (sharedObject) &#123; while (condition) &#123; sharedObject.wait();// (Releases lock, and reacquires on wakeup) &#125; ...// do action based upon condition e.g. take or put into queue&#125; 正如我建议的，我们应该在一个循环中调用wait。这个循环用于在线程休眠之前和之后检查condition。 Java中使用wait(),notify(),notifyAll()的例子下面是在Java中使用wait(),notify(),notifyAll()的例子。在这个程序中，有两个线程(PRODUCTOR和CONSUMER)，用继承了Thread类的Producer和Consumer类实现。Prodcuer和Consumer的业务逻辑写在他们各自的run()方法中。并且实现一个LinkedList，当做共享队列。Producer在一个死循环中不断在队列中插入随机数，直到队列满了。我们会检查while(queue.size == maxSize),需要注意的是在检查之前需要给队列加上同步锁以保证在检查时没有另一个线程修改队列。如果队列满了，PRODUCER线程就会休眠，直到CONSUMER消费了队列中的元素并且调用notify()方法通知PRODUCER线程。wait和notify都是在共享的对象(我们的例子中是队列)上调用的。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113import java.util.LinkedList;import java.util.Queue;import java.util.Random;/** * Simple Java program to demonstrate How to use wait, notify and notifyAll() * method in Java by solving producer consumer problem. * * @author Javin Paul */public class MultipleThread &#123; public static void main(String args[]) &#123; System.out.println(\"How to use wait and notify method in Java\"); System.out.println(\"Solving Producer Consumper Problem\"); Queue&lt;Integer&gt; buffer = new LinkedList&lt;&gt;(); int maxSize = 10; Thread producer = new Producer(buffer, maxSize, \"PRODUCER\"); Thread consumer = new Consumer(buffer, maxSize, \"CONSUMER\"); producer.start(); consumer.start(); &#125;&#125;/** * Producer Thread will keep producing values for Consumer * to consumer. It will use wait() method when Queue is full * and use notify() method to send notification to Consumer * Thread. * @author WINDOWS 8 * */class Producer extends Thread &#123; private Queue&lt;Integer&gt; queue; private int maxSize; public Producer(Queue&lt;Integer&gt; queue, int maxSize, String name) &#123; super(name); this.queue = queue; this.maxSize = maxSize; &#125; @Override public void run() &#123; while (true) &#123; synchronized (queue) &#123; while (queue.size() == maxSize) &#123; try &#123; System.out .println(\"Queue is full, \" + \"Producer thread waiting for \" + \"consumer to take something from queue\"); queue.wait(); &#125; catch (Exception ex) &#123; ex.printStackTrace(); &#125; &#125; Random random = new Random(); int i = random.nextInt(); System.out.println(\"Producing value : \" + i); queue.add(i); queue.notifyAll(); &#125; &#125; &#125;&#125;/** * Consumer Thread will consumer values form shared queue. * It will also use wait() method to wait if queue is * empty. It will also use notify method to send * notification to producer thread after consuming values * from queue. * @author WINDOWS 8 **/class Consumer extends Thread &#123; private Queue&lt;Integer&gt; queue; private int maxSize; public Consumer(Queue&lt;Integer&gt; queue, int maxSize, String name)&#123; super(name); this.queue = queue; this.maxSize = maxSize; &#125; @Override public void run() &#123; while (true) &#123; synchronized (queue) &#123; while (queue.isEmpty()) &#123; System.out.println(\"Queue is empty,\" + \"Consumer thread is waiting\" + \" for producer thread to put something in queue\"); try &#123; queue.wait(); &#125; catch (Exception ex) &#123; ex.printStackTrace(); &#125; &#125; System.out.println(\"Consuming value : \" + queue.remove()); queue.notifyAll(); &#125; &#125; &#125;&#125;Output How to use wait and notify method in Java Solving Producer Consumper Problem Queue is empty,Consumer thread is waiting for producer thread to put something in queue Producing value : -1692411980 Producing value : 285310787 Producing value : -1045894970 Producing value : 2140997307 Producing value : 1379699468 Producing value : 912077154 Producing value : -1635438928 Producing value : -500696499 Producing value : -1985700664 Producing value : 961945684 Queue is full, Producer thread waiting for consumer to take something from queue Consuming value : -1692411980 Consuming value : 285310787 Consuming value : -1045894970 Consuming value : 2140997307 Consuming value : 1379699468 Consuming value : 912077154 Consuming value : -1635438928 Consuming value : -500696499 Consuming value : -1985700664 Consuming value : 961945684 Queue is empty,Consumer thread is waiting for producer thread to put something in queue 为了更好的理解这个程序，我建议大家使用debug模式运行。 使用wait，notify，notifyAll需要注意的 在Java中可以使用wait，notify，notifyAll完成多线程(不仅仅是两个线程)的内部通信。 在同步方法或同步块中使用wait，notify，notifyAll，否则JVM会抛出IllegalMonitorStateException 在循环中调用wait，notify。 在线程共享的对象上调用wait 偏向选择notifyAll，而不是notify，原因在这篇文章里","raw":null,"content":null,"categories":[{"name":"java","slug":"java","permalink":"http://yemengying.com/categories/java/"},{"name":"thread","slug":"java/thread","permalink":"http://yemengying.com/categories/java/thread/"}],"tags":[{"name":"java","slug":"java","permalink":"http://yemengying.com/tags/java/"},{"name":"翻译","slug":"翻译","permalink":"http://yemengying.com/tags/翻译/"}]},{"title":"使用基于注解的mybatis时,利用反射和注解生成sql语句","slug":"基于注解的mybatis插入对象时利用反射生成sql语句","date":"2015-10-28T05:21:29.000Z","updated":"2016-04-23T02:06:45.000Z","comments":true,"path":"2015/10/28/基于注解的mybatis插入对象时利用反射生成sql语句/","link":"","permalink":"http://yemengying.com/2015/10/28/基于注解的mybatis插入对象时利用反射生成sql语句/","excerpt":"在开发时遇到一个问题，在使用基于注解的mybatis插入一个对象到mysql时，在写sql语句时需要列出对象的所有属性，所以在插入一个拥有10个以上属性的对象时sql语句就会变得很长，写起来也很不方便,也很容易拼错。google了一下也没有找到什么解决方式(可能是姿势不对😜)，在stackoverflow上提的问题截止目前还没有人回答。所以自己想了一个基于反射和注解的解决办法git地址： loadStyle(\"/hexo-github/style.css\"); loadStyle(\"/hexo-github/octicons/octicons.css\"); new Badge(\"#badge-container-giraffe0813-spring-mybatis-utils-a555c91\", \"giraffe0813\", \"spring-mybatis-utils\", \"a555c91\", false);","keywords":null,"text":"在开发时遇到一个问题，在使用基于注解的mybatis插入一个对象到mysql时，在写sql语句时需要列出对象的所有属性，所以在插入一个拥有10个以上属性的对象时sql语句就会变得很长，写起来也很不方便,也很容易拼错。google了一下也没有找到什么解决方式(可能是姿势不对😜)，在stackoverflow上提的问题截止目前还没有人回答。所以自己想了一个基于反射和注解的解决办法git地址： loadStyle(\"/hexo-github/style.css\"); loadStyle(\"/hexo-github/octicons/octicons.css\"); new Badge(\"#badge-container-giraffe0813-spring-mybatis-utils-a555c91\", \"giraffe0813\", \"spring-mybatis-utils\", \"a555c91\", false); 下面是之前的代码片段: 123@Insert(\"insert into poi_shop(name,brand,tags,status,phone,mobile,business_time,address,city,lng,lat,business_type,attribute_json) values(#&#123;name&#125;,#&#123;brand&#125;,#&#123;tags&#125;,#&#123;status&#125;,#&#123;phone&#125;,#&#123;mobile&#125;,#&#123;business_time&#125;,#&#123;address&#125;,#&#123;city&#125;,#&#123;lng&#125;,#&#123;lat&#125;,#&#123;business_type&#125;,#&#123;attribute_json&#125;)\")@Options(useGeneratedKeys = true, keyProperty = \"id\", keyColumn = \"id\")public Long insertPoiInfo(PoiBo poiBo); 是不是too looooooooooooong： 第一版(利用反射)首先想到的是可以利用反射获得对象的所有属性，然后拼接成sql语句。所以写了一个基于反射拼装sql语句的方法，然后基于mybatis动态获得sql语句的方式 获得完整的sql 具体的代码如下:接口层改为下面的样子，sql语句的生成放到PoiSqlProvider的insertPoiBo方法中 12@InsertProvider(type = PoiSqlProvider.class, method = \"insertPoiBo\")public Long insertPoiInfo(@Param(\"poiBo\")PoiBo poiBo); PoiSqlProvider.class 1234567891011121314151617181920212223242526272829303132333435363738 public String insertPoiBo(Map&lt;String,Object&gt; map)&#123; PoiBo poiBo = (PoiBo)map.get(\"poiBo\"); StringBuilder sql = new StringBuilder(\"insert into poi_shop \"); //get sql via reflection Map&lt;String,String&gt; sqlMap = getAllPropertiesForSql(poiBo, \"poiBo\"); // sql.append(sqlMap.get(\"field\")).append(sqlMap.get(\"value\")); System.out.println(sql.toString()); return sql.toString(); &#125;//根据传入的对象 基于反射生成两部分sql语句 private Map&lt;String,String&gt; getAllPropertiesForSql(Object obj, String objName)&#123; Map&lt;String,String&gt; map = new HashMap&lt;String,String&gt;(); if(null == obj) return map; StringBuilder filedSql = new StringBuilder(\"(\"); StringBuilder valueSql = new StringBuilder(\"value (\"); Field[] fields = obj.getClass().getDeclaredFields(); for (int i = 0; i &lt; fields.length; i++) &#123; filedSql.append(fields[i].getName() + \",\"); valueSql.append(\"#&#123;\" + objName + \".\" + fields[i].getName() + \"&#125;,\"); &#125; //remove last ',' valueSql.deleteCharAt(valueSql.length() - 1); filedSql.deleteCharAt(filedSql.length() - 1); valueSql.append(\") \"); filedSql.append(\") \"); map.put(\"field\",filedSql.toString()); map.put(\"value\", valueSql.toString()); System.out.println(\"database filed sql: \" + filedSql.toString()); System.out.println(\"value sql:\" + valueSql.toString()); return map; &#125; 下面是基于反射生成的两部分sq语句和最后拼接的语句 123456789database filed sql: (id,name,brand,tags,status,phone,mobile,business_time,address,city,lng,lat,business_type,attribute_json,updated_at,created_at) value sql:value(#&#123;poiBo.id&#125;,#&#123;poiBo.name&#125;,#&#123;poiBo.brand&#125;,#&#123;poiBo.tags&#125;,#&#123;poiBo.status&#125;,#&#123;poiBo.phone&#125;,#&#123;poiBo.mobile&#125;,#&#123;poiBo.business_time&#125;,#&#123;poiBo.address&#125;,#&#123;poiBo.city&#125;,#&#123;poiBo.lng&#125;,#&#123;poiBo.lat&#125;,#&#123;poiBo.business_type&#125;,#&#123;poiBo.attribute_json&#125;,#&#123;poiBo.updated_at&#125;,#&#123;poiBo.created_at&#125;) insert into poi_shop (id,name,brand,tags,status,phone,mobile,business_time,address,city,lng,lat,business_type,attribute_json,updated_at,created_at) value (#&#123;poiBo.id&#125;,#&#123;poiBo.name&#125;,#&#123;poiBo.brand&#125;,#&#123;poiBo.tags&#125;,#&#123;poiBo.status&#125;,#&#123;poiBo.phone&#125;,#&#123;poiBo.mobile&#125;,#&#123;poiBo.business_time&#125;,#&#123;poiBo.address&#125;,#&#123;poiBo.city&#125;,#&#123;poiBo.lng&#125;,#&#123;poiBo.lat&#125;,#&#123;poiBo.business_type&#125;,#&#123;poiBo.attribute_json&#125;,#&#123;poiBo.updated_at&#125;,#&#123;poiBo.created_at&#125;) 要注意的是如果数据库的字段名和插入对象的属性名不一致，那么不能使用生成的database filed sql。 最终版(加入注解)上面的getAllPropertiesForSql方法有个缺点，如果数据库的字段名和类的属性名不一致，就不能依靠反射获得sql了。所以借鉴老大的ORM框架也写了一个注解Column，用于model类的属性上，表明属性所对应数据库字段。下面是Column注解的snippet。 123456789101112131415161718import java.lang.annotation.ElementType;import java.lang.annotation.Retention;import java.lang.annotation.RetentionPolicy;import java.lang.annotation.Target;/* 定义字段的注解*/@Retention(RetentionPolicy.RUNTIME)/*该注解只能用在成员变量上*/@Target(ElementType.FIELD)public @interface Column &#123; /** * 用来存放字段的名字 如果未指定列名，默认列名使用成员变量名 * * @return */ String name() default \"\"; &#125; 之后在model类属性上加入对应的注解,省略getter和setter。Column的name为空时，代表属性名和字段名一致。 1234567891011121314151617181920212223242526272829303132333435363738public class PoiBo &#123; @Column private Long id; @Column(name = \"poi_name\") private String name;//表示name属性对应数据库poi_name字段 @Column(name = \"poi_brand\") private String brand;//表示brand属性对应数据库poi_brand字段 @Column private String tags; @Column private Integer status; @Column private String phone; @Column private String mobile; @Column private String business_time; @Column private Float average_price; @Column private String address; @Column private String city; @Column private Double lng; @Column private Double lat; @Column private String business_type; @Column private String attribute_json; @Column private Timestamp updated_at; @Column private Timestamp created_at; &#125; 修改getAllPropertiesForSql方法，通过获取类属性上的注解获得数据库字段名。 12345678910111213141516171819202122232425262728293031323334353637383940private Map&lt;String,String&gt; getAllPropertiesForSql(Object obj, String objName)&#123; Map&lt;String,String&gt; map = new HashMap&lt;String,String&gt;(); if(null == obj) return map; StringBuilder filedSql = new StringBuilder(\"(\"); StringBuilder valueSql = new StringBuilder(\"value (\"); Field[] fields = obj.getClass().getDeclaredFields(); for (Field field : fields) &#123; // 判断该成员变量上是不是存在Column类型的注解 if (!field.isAnnotationPresent(Column.class)) &#123; continue; &#125; Column c = field.getAnnotation(Column.class);// 获取实例 // 获取元素值 String columnName = c.name(); // 如果未指定列名，默认列名使用成员变量名 if (\"\".equals(columnName.trim())) &#123; columnName = field.getName(); &#125; filedSql.append(columnName + \",\"); valueSql.append(\"#&#123;\" + objName + \".\" + field.getName() + \"&#125;,\"); &#125; //remove last ',' valueSql.deleteCharAt(valueSql.length() - 1); filedSql.deleteCharAt(filedSql.length() - 1); valueSql.append(\") \"); filedSql.append(\") \"); map.put(\"field\",filedSql.toString()); map.put(\"value\", valueSql.toString()); System.out.println(\"database filed sql: \" + filedSql.toString()); System.out.println(\"value sql:\" + valueSql.toString()); return map; &#125;` 利用反射+注解之后的输出结果，可以看到sql语句正确按照name的Column注解的输出了name属性对应的数据库字段是poi_name. 123456789database filed sql: (id,poi_name,poi_brand,tags,status,phone,mobile,business_time,average_price,address,city,lng,lat,business_type,attribute_json,updated_at,created_at) value sql:value(#&#123;poiBo.id&#125;,#&#123;poiBo.name&#125;,#&#123;poiBo.brand&#125;,#&#123;poiBo.tags&#125;,#&#123;poiBo.status&#125;,#&#123;poiBo.phone&#125;,#&#123;poiBo.mobile&#125;,#&#123;poiBo.business_time&#125;,#&#123;poiBo.average_price&#125;,#&#123;poiBo.address&#125;,#&#123;poiBo.city&#125;,#&#123;poiBo.lng&#125;,#&#123;poiBo.lat&#125;,#&#123;poiBo.business_type&#125;,#&#123;poiBo.attribute_json&#125;,#&#123;poiBo.updated_at&#125;,#&#123;poiBo.created_at&#125;) insert into poi_shop (id,poi_name,poi_brand,tags,status,phone,mobile,business_time,average_price,address,city,lng,lat,business_type,attribute_json,updated_at,created_at) value (#&#123;poiBo.id&#125;,#&#123;poiBo.name&#125;,#&#123;poiBo.brand&#125;,#&#123;poiBo.tags&#125;,#&#123;poiBo.status&#125;,#&#123;poiBo.phone&#125;,#&#123;poiBo.mobile&#125;,#&#123;poiBo.business_time&#125;,#&#123;poiBo.average_price&#125;,#&#123;poiBo.address&#125;,#&#123;poiBo.city&#125;,#&#123;poiBo.lng&#125;,#&#123;poiBo.lat&#125;,#&#123;poiBo.business_type&#125;,#&#123;poiBo.attribute_json&#125;,#&#123;poiBo.updated_at&#125;,#&#123;poiBo.created_at&#125;) 写的好累放张萌图吧","raw":null,"content":null,"categories":[{"name":"java","slug":"java","permalink":"http://yemengying.com/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"http://yemengying.com/tags/java/"},{"name":"mybatis","slug":"mybatis","permalink":"http://yemengying.com/tags/mybatis/"},{"name":"reflection","slug":"reflection","permalink":"http://yemengying.com/tags/reflection/"},{"name":"anntation","slug":"anntation","permalink":"http://yemengying.com/tags/anntation/"}]},{"title":"【译】如何重置一个ArrayList--clear vs removeAll","slug":"译-如何重置一个ArrayList-clear-vs-removeAll","date":"2015-10-26T15:20:04.000Z","updated":"2016-04-22T13:44:02.000Z","comments":true,"path":"2015/10/26/译-如何重置一个ArrayList-clear-vs-removeAll/","link":"","permalink":"http://yemengying.com/2015/10/26/译-如何重置一个ArrayList-clear-vs-removeAll/","excerpt":"安利一个APP–开发者头条，在上面发现一个不错的英文技术类博客，地址http://javarevisited.blogspot.com/， 会不定期的翻译一些 翻译不好见谅啊😼 原文地址：http://javarevisited.blogspot.co.uk/2015/09/how-to-reset-arraylist-in-java-clear-vs-removeAll-example.html 很多时候为了重用我们会想要重置一个ArrayList，这里的重置是指清空列表或移除列表所有的元素。在Java中，有两个方法可以帮助我们实现重置clear或removeAll。在列表长度很小的情况下(eg:10或100个元素)，可以放心的使用这两种方法。但如果列表很大(eg:10M个元素)，那么选择clear还是removeAll会对你java应用的性能造成巨大的影响。甚至有时，在列表过大的情况下，重置会耗费许多时间，那么重新创建一个新的列表比将老的列表重置要好。但需要提醒的是，必须要确保老的列表可以被垃圾回收，否则，有很大的风险会出现java.lang.OutOfMemoryError: Java Heap Space。言归正传，让我们看看clear()和removeAll()两个方法。大家应该常常会选择用clear(),因为他的复杂度是O(n),而相比之下，removeAll(Collection C)的性能要差一些，它的复杂度是O(n^2)。这也是为什么在重置大的列表的时候两个方法会有巨大的差异。如果阅读他们的源码并运行下面的例子程序，差异会更明显。","keywords":null,"text":"安利一个APP–开发者头条，在上面发现一个不错的英文技术类博客，地址http://javarevisited.blogspot.com/， 会不定期的翻译一些 翻译不好见谅啊😼 原文地址：http://javarevisited.blogspot.co.uk/2015/09/how-to-reset-arraylist-in-java-clear-vs-removeAll-example.html 很多时候为了重用我们会想要重置一个ArrayList，这里的重置是指清空列表或移除列表所有的元素。在Java中，有两个方法可以帮助我们实现重置clear或removeAll。在列表长度很小的情况下(eg:10或100个元素)，可以放心的使用这两种方法。但如果列表很大(eg:10M个元素)，那么选择clear还是removeAll会对你java应用的性能造成巨大的影响。甚至有时，在列表过大的情况下，重置会耗费许多时间，那么重新创建一个新的列表比将老的列表重置要好。但需要提醒的是，必须要确保老的列表可以被垃圾回收，否则，有很大的风险会出现java.lang.OutOfMemoryError: Java Heap Space。言归正传，让我们看看clear()和removeAll()两个方法。大家应该常常会选择用clear(),因为他的复杂度是O(n),而相比之下，removeAll(Collection C)的性能要差一些，它的复杂度是O(n^2)。这也是为什么在重置大的列表的时候两个方法会有巨大的差异。如果阅读他们的源码并运行下面的例子程序，差异会更明显。 Clear() vs RemoveAll(Collection c)为了更好的比较这两个方法，阅读他们源码是很重要的。可以在java.utils.ArrayList类中找到clear()方法，不过为了方便我将它引入到了这里。下面的代码来自JDK 1.7.0_40版本。如果你想要学习更多的有关性能监控和调优的知识，我强烈建议阅读Scott Oaks写的Java Performance the Definitive Guide,它包含了java 7和一点java 8。下面是clear()的代码片段: 12345678910/** * Removes all of the elements from this list.The list will * be empty after this call returns. */ public void clear() &#123; modCount++; // clear to let GC do its work for (int i = 0; i &lt; size; i++) elementData[i] = null; size = 0; &#125; 大家可以看出，clear()在循环遍历ArrayList，并且将每一个元素都置为null，使它们在没有被外部引用的情况下可以被垃圾回收。相似的，我们可以在java.util.AbstractCollection类中查看removeAll(Collention c)的代码，下面是代码片段: 12345678910111213public boolean removeAll(Collection&lt;?&gt; c) &#123; //判断对象是否为null Objects.requireNonNull(c); boolean modified = false; Iterator&lt;?&gt; it = iterator(); while (it.hasNext()) &#123; if (c.contains(it.next())) &#123; it.remove(); modified = true; &#125; &#125; return modified; &#125; 这个方法会检查迭代器顺序返回的每个元素是否包含在特定的集合中。如果存在，调用迭代器的remove方法将它从集合中移除。因为会用到contains方法，removeAll的复杂度是O(n^2)。所以在想要重置一个大的ArrayList时，这种方法是绝对不可取的。下面我们比较一下两者在重置一个包含100K个元素时的性能差异。 删除一个包含100k个元素的列表中的所有元素我本来想在例子中尝试重置一个包含10M个元素的列表，不过在超过半个小时等待removeAll()结束后，我决定将元素的数量降为100K。在这种情况下，两个方法的差距也是很明显的。removeAll()比clear()多花费了10000倍的时间。事实上，在API中clear()和removeAll(Collection c)这两个方法的目的是不同的。clear()方法是为了通过删除所有元素而重置列表，而removeAll(Collection c)是为了从集合中删除某些存在于另一个提供的集合中的元素，并不是为了从集合中移除所有元素。所以如果你的目的是删除所有元素，用clear(),如果你的目的是删除某些存在于另一集合的元素，那么选择removeAll(Collection c)方法。 1234567891011121314151617181920212223242526272829303132333435import java.util.ArrayList; /** * Java Program to remove all elements from list in Java and comparing * performance of clearn() and removeAll() method. * * @author Javin Paul */ public class ArrayListResetTest &#123; private static final int SIZE = 100_000; public static void main(String args[]) &#123; // Two ArrayList for clear and removeAll ArrayList numbers = new ArrayList(SIZE); ArrayList integers = new ArrayList(SIZE); // Initialize ArrayList with 10M integers for (int i = 0; i &amp;lt; SIZE; i++) &#123; numbers.add(new Integer(i)); integers.add(new Integer(i)); &#125; // Empty ArrayList using clear method long startTime = System.nanoTime(); numbers.clear(); long elapsed = System.nanoTime() - startTime; System.out.println(\"Time taken by clear to empty ArrayList of 1M elements (ns): \" + elapsed); // Reset ArrayList using removeAll method startTime = System.nanoTime(); integers.removeAll(integers); long time = System.nanoTime() - startTime; System.out.println(\"Time taken by removeAll to reset ArrayList of 1M elements (ns): \" + time); &#125; &#125; Output: Time taken by clear to empty ArrayList of 100000 elements (ns): 889619 Time taken by removeAll to reset ArrayList of 100000 elements (ns): 36633112126 由于程序使用了两个arrayList存储Integers，所以在运行时要确保有足够的内存，尤其是你想比较在列表存有1M个元素时，两种方法的性能差异。另外，由于使用了在数字中加入下划线的特性，所以需要java7来运行。如果没有JDK7，也可以移除SIZE常量中的下划线。 以上就是关于如何重置一个ArrayList的内容。我们不仅仅学到了两种从列表中删除元素的方法，也学到了clear()和removeAll()方法的区别。我们明白了为什么在列表过大时，removeAll()性能很差。 PS：当使用clear()方法也消耗很长的时间时，考虑创建一个新的列表，因为java可以很快的创建一个新的对象。 扩展阅读： ArrayList and HashMap Performance Improvement in JDK 7 How to convert ArrayList to Set? How to sort an ArrayList in reverse order in Java? How to remove duplicate elements from ArrayList in Java? How to clone an ArrayList in Java? How do you convert a Map to List in Java? Performance comparison of contains() vs binarySearch() How to initialize an ArrayList with values in Java? The ArrayList Guide The difference between an ArrayList and a Vector in Java? How to make an ArrayList unmodifiable in Java?","raw":null,"content":null,"categories":[{"name":"java","slug":"java","permalink":"http://yemengying.com/categories/java/"},{"name":"list","slug":"java/list","permalink":"http://yemengying.com/categories/java/list/"}],"tags":[{"name":"java","slug":"java","permalink":"http://yemengying.com/tags/java/"},{"name":"翻译","slug":"翻译","permalink":"http://yemengying.com/tags/翻译/"}]},{"title":"Mac系统下Idea和STS的快捷键对比","slug":"Idea和STS的快捷键对比","date":"2015-10-23T08:15:42.000Z","updated":"2016-02-02T06:34:22.000Z","comments":true,"path":"2015/10/23/Idea和STS的快捷键对比/","link":"","permalink":"http://yemengying.com/2015/10/23/Idea和STS的快捷键对比/","excerpt":"","keywords":null,"text":"又被朋友安利了一遍Idea 所以决定尝试着把IDE由STS切换成Idea。不过发现好多快捷键都不一致，所以在熟悉Idea的过程中顺便记录一下两者的常用快捷键对比 STS(Spring Tool Suite) Idea Run shift+command+F11 shift + control + r Debug command + F11 shift + control + d 复制当前行 alt + command + 向下方向键 command + d 剪贴当前行 command + x command + x 删除当前行 command + d command + x 搜索 command + f command + f 搜索替换 command + f command + r Preferences command + , command + , 光标移到代码块最后 option+command+] 光标移到代码块最前 option+command+[ Rename alt+command+r shift+F6 所选语句上移 option+向上方向键 shift+command+向上方向键 所选语句下移 option+向下方向键 shift+command+向下方向键 选择实现父类的方法 control+o generate(setter/constructor/toString) option+command+s command+n step over F6 F8 step into F5 F7 step out F7 shift+F8 stop option+command+s command+F2","raw":null,"content":null,"categories":[{"name":"java","slug":"java","permalink":"http://yemengying.com/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"http://yemengying.com/tags/java/"},{"name":"STS","slug":"STS","permalink":"http://yemengying.com/tags/STS/"},{"name":"Idea","slug":"Idea","permalink":"http://yemengying.com/tags/Idea/"}]},{"title":"使代码更简洁(三)---利用Builder Pattern为对象属性赋值","slug":"使代码更简洁-三-利用方法链为对象属性赋值","date":"2015-09-26T07:18:12.000Z","updated":"2016-04-22T13:43:49.000Z","comments":true,"path":"2015/09/26/使代码更简洁-三-利用方法链为对象属性赋值/","link":"","permalink":"http://yemengying.com/2015/09/26/使代码更简洁-三-利用方法链为对象属性赋值/","excerpt":"以前写在segmentFault上的一篇文章，搬移到这里 有一个有很多属性的类，在为它的属性赋值时，通常有两种方式，使用构造函数和使用set方法。可是使用构造函数有时会忘了各个字段的顺序 ，直接使用set方法，又比较麻烦。所以同事提出可以使用方法链。","keywords":null,"text":"以前写在segmentFault上的一篇文章，搬移到这里 有一个有很多属性的类，在为它的属性赋值时，通常有两种方式，使用构造函数和使用set方法。可是使用构造函数有时会忘了各个字段的顺序 ，直接使用set方法，又比较麻烦。所以同事提出可以使用方法链。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273public class User &#123; private int id; private String name; private int age; private int sex; private int cityId; private int buId; private int roleId; private String pinyinName; public String getPinyinName() &#123; return pinyinName; &#125; public void setPinyinName(String pinyinName) &#123; this.pinyinName = pinyinName; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125; public int getSex() &#123; return sex; &#125; public void setSex(int sex) &#123; this.sex = sex; &#125; public int getCityId() &#123; return cityId; &#125; public void setCityId(int cityId) &#123; this.cityId = cityId; &#125; public int getBuId() &#123; return buId; &#125; public void setBuId(int buId) &#123; this.buId = buId; &#125; public int getRoleId() &#123; return roleId; &#125; public void setRoleId(int roleId) &#123; this.roleId = roleId; &#125; public int getId() &#123; return id; &#125; public void setId(int id) &#123; this.id = id; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public User(int id, String name, int age, int sex, int cityId, int buId, int roleId, String pinyinName) &#123; super(); this.id = id; this.name = name; this.age = age; this.sex = sex; this.cityId = cityId; this.buId = buId; this.roleId = roleId; this.pinyinName = pinyinName; &#125; &#125; 类似于StringBuilder的append方法 12String s = new StringBuilder().append(\"0\").append(1) .append(\" 2 \").append(3).toString(); 让bean的每个属性的set方法都返回一个对象本身的引用，将User类的set方法改写成下面的样子： 123456789101112131415161718192021222324252627282930313233343536373839public User setId(int id) &#123; this.id = id; return this; &#125; public User setName(String name) &#123; this.name = name; return this; &#125; public User setAge(int age) &#123; this.age = age; return this; &#125; public User setSex(int sex) &#123; this.sex = sex; return this; &#125; public User setCityId(int cityId) &#123; this.cityId = cityId; return this; &#125; public User setBuId(int buId) &#123; this.buId = buId; return this; &#125; public User setRoleId(int roleId) &#123; this.roleId = roleId; return this; &#125; public User setPinyinName(String pinyinName) &#123; this.pinyinName = pinyinName; return this; &#125; 这样在对User的属性赋值时就简洁了许多。 1234567User user = new User().setId(1).setAge(18) .setBuId(127) .setRoleId(12) .setName(\"giraffe\") .setCityId(12) .setSex(1) .setPinyinName(\"gif\"); 大部分IDE默认生成无返回值的setter，不过Idea也支持生成返回this对象的方式。在生成setter时把template由default改为builder。如下图: 不过不知道这样写会不会有什么不好的地方~~","raw":null,"content":null,"categories":[{"name":"java","slug":"java","permalink":"http://yemengying.com/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"http://yemengying.com/tags/java/"}]},{"title":"spring结合rabbitmq---简单的demo","slug":"spring结合rabbitmq-简单的demo","date":"2015-09-19T06:55:43.000Z","updated":"2016-04-23T02:04:27.000Z","comments":true,"path":"2015/09/19/spring结合rabbitmq-简单的demo/","link":"","permalink":"http://yemengying.com/2015/09/19/spring结合rabbitmq-简单的demo/","excerpt":"在做搜索服务时，当业务方数据源改变时，需要改变搜索引擎中索引的数据。可以定时拉取也可以实时推送。为了实现同步更新，选择了实时推送。实时推送也有两种方式，一种是提供索引更新接口供业务方调用，在接口中将变化的数据更新到搜索引擎中；另一种是使用消息队列，业务方在数据改变时，将改变的数据插入队列，服务端的消费者实时监听队列，并进行索引更新。考虑到使用消息队列有三点好处，选择了第二种方式。使用消息队列的好处: 一，使用消息队列可以异步处理更新操作降低接口响应时间；二，对于消费端由于不可预测原因导致消息无法处理时，数据可以暂存在队列中，等消费者服务恢复后可以继续处理历史数据,提高可用性；三，将业务方的服务和索引更新服务解耦。下面简单记录一下一个简单的spring+rabbitmq的demo实现，只实现了简单的消息生产和消费。 参考了下面几篇博客：http://syntx.io/getting-started-with-rabbitmq-using-the-spring-framework/https://blog.codecentric.de/en/2011/04/amqp-messaging-with-rabbitmq/http://wb284551926.iteye.com/blog/2212869","keywords":null,"text":"在做搜索服务时，当业务方数据源改变时，需要改变搜索引擎中索引的数据。可以定时拉取也可以实时推送。为了实现同步更新，选择了实时推送。实时推送也有两种方式，一种是提供索引更新接口供业务方调用，在接口中将变化的数据更新到搜索引擎中；另一种是使用消息队列，业务方在数据改变时，将改变的数据插入队列，服务端的消费者实时监听队列，并进行索引更新。考虑到使用消息队列有三点好处，选择了第二种方式。使用消息队列的好处: 一，使用消息队列可以异步处理更新操作降低接口响应时间；二，对于消费端由于不可预测原因导致消息无法处理时，数据可以暂存在队列中，等消费者服务恢复后可以继续处理历史数据,提高可用性；三，将业务方的服务和索引更新服务解耦。下面简单记录一下一个简单的spring+rabbitmq的demo实现，只实现了简单的消息生产和消费。 参考了下面几篇博客：http://syntx.io/getting-started-with-rabbitmq-using-the-spring-framework/https://blog.codecentric.de/en/2011/04/amqp-messaging-with-rabbitmq/http://wb284551926.iteye.com/blog/2212869 本地安装rabbitmq只介绍mac系统下如何安装 安装brew1ruby -e &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)&quot; 利用brew安装rabbitmq1.输入命令 1brew install rabbitmq 2.添加配置 1export PATH=$PATH:$(brew --prefix)/sbin 3.可以禁用用不着的插件 12rabbitmq-plugins disable --offline rabbitmq_stomprabbitmq-plugins disable --offline rabbitmq_mqtt 4.启动rabbitmq server 直接输入下面的命令 1rabbitmq-server 5.如果打印出下面的东东就是启动成功了，默认端口是5672 实现demo首先要有个可以运行的spring + maven的项目 添加maven依赖在pom文件中添加rabbitmq相关的依赖 12345678910&lt;dependency&gt; &lt;groupId&gt;com.rabbitmq&lt;/groupId&gt; &lt;artifactId&gt;amqp-client&lt;/artifactId&gt; &lt;version&gt;3.5.4&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.amqp&lt;/groupId&gt; &lt;artifactId&gt;spring-rabbit&lt;/artifactId&gt; &lt;version&gt;1.5.0.RELEASE&lt;/version&gt;&lt;/dependency&gt; 添加配置文件12345678910111213141516171819202122232425262728293031323334&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xmlns:rabbit=\"http://www.springframework.org/schema/rabbit\" xmlns:p=\"http://www.springframework.org/schema/p\" xsi:schemaLocation=\"http://www.springframework.org/schema/beanshttp://www.springframework.org/schema/beans/spring-beans-4.0.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-4.0.xsd http://www.springframework.org/schema/rabbit http://www.springframework.org/schema/rabbit/spring-rabbit.xsd\"&gt; &lt;!-- 扫描包 --&gt; &lt;context:component-scan base-package=\"ymy.com.rabbitmq.demo.service.impl.*\" /&gt; &lt;context:annotation-config /&gt; &lt;!-- 连接本地rabbitmq --&gt; &lt;rabbit:connection-factory id=\"connectionFactory\" host=\"localhost\" port=\"5672\" /&gt; &lt;rabbit:admin connection-factory=\"connectionFactory\" id=\"amqpAdmin\" /&gt; &lt;!-- queue 队列声明 --&gt; &lt;rabbit:queue id=\"rabbit_queue_one\" durable=\"true\" auto-delete=\"false\" exclusive=\"false\" name=\"rabbit_queue_one\" /&gt; &lt;!-- exchange queue binging key 绑定 --&gt; &lt;rabbit:direct-exchange name=\"mq-exchange\" durable=\"true\" auto-delete=\"false\" id=\"mq-exchange\"&gt; &lt;rabbit:bindings&gt; &lt;rabbit:binding queue=\"rabbit_queue_one\" key=\"rabbit_queue_one\" /&gt; &lt;/rabbit:bindings&gt; &lt;/rabbit:direct-exchange&gt; &lt;!-- spring template声明 --&gt; &lt;rabbit:template exchange=\"mq-exchange\" id=\"amqpTemplate\" connection-factory=\"connectionFactory\" /&gt;&lt;/beans&gt; 生产者开发（插入消息）123456789101112131415161718192021222324package ymy.com.rabbitmq.demo.service.impl;import org.springframework.amqp.core.AmqpAdmin;import org.springframework.amqp.core.AmqpTemplate;import org.springframework.amqp.core.Message;import org.springframework.amqp.rabbit.connection.ConnectionFactory;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Service;@Service(\"messageProductorService\")public class MessageProductorService &#123; @Autowired private AmqpAdmin admin; @Autowired private AmqpTemplate amqpTemplate; @Autowired private ConnectionFactory connectionFactory; public void pushToMessageQueue(String routingKey, String message) &#123; amqpTemplate.convertAndSend(routingKey, message); &#125;&#125; 消费者开发有两种方式从消息队列中获取消息，一种是自己调用receive方法获得，一种是为队列配置监听类，每当监听的队列中有消息产生，就会被监听的类去除。第一种方式： 12345678910111213141516package ymy.com.rabbitmq.demo.service.impl;import org.springframework.amqp.core.AmqpTemplate;import org.springframework.amqp.core.Message;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Service;@Service(\"messageConsumerService\")public class MessageConsumerService &#123; @Autowired private AmqpTemplate amqpTemplate; public void popMessage(String destinationQueueName) &#123; Message message = amqpTemplate.receive(destinationQueueName); System.out.println(new String(message.getBody())); &#125;&#125; junit test 12345@Testpublic void testMessageQueueManager()&#123; messageProductor.pushToMessageQueue(\"rabbit_queue_one\", \"hello giraffe\"); messageConsumer.popMessage(\"rabbit_queue_one\");&#125; 第二种方式配置中添加监听 1234&lt;!-- queue litener 观察 监听模式 当有消息到达时会通知监听在对应的队列上的监听对象 taskExecutor这个需要自己实现一个连接池 按照官方说法 除非特别大的数据量 一般不需要连接池--&gt; &lt;rabbit:listener-container connection-factory=\"connectionFactory\" acknowledge=\"auto\" &gt; &lt;rabbit:listener queues=\"rabbit_queue_one\" ref=\"messageConsumerService\"/&gt; &lt;/rabbit:listener-container&gt; 消费者类需要实现MessageListener 并实现onMessage方法，当监听的队列中有消息进入时，onMessage方法会被调用 1234567891011121314package ymy.com.rabbitmq.demo.service.impl;import org.springframework.amqp.core.Message;import org.springframework.stereotype.Service;import org.springframework.amqp.core.MessageListener;@Service(\"messageConsumerService\")public class MessageConsumerService implements MessageListener&#123; @Override public void onMessage(Message message) &#123; System.out.println(\"成功取出消息\" + new String(message.getBody())); &#125;&#125; git 地址： loadStyle(\"/hexo-github/style.css\"); loadStyle(\"/hexo-github/octicons/octicons.css\"); new Badge(\"#badge-container-giraffe0813-spring-rabbit-demo-617348a\", \"giraffe0813\", \"spring-rabbit-demo\", \"617348a\", false);","raw":null,"content":null,"categories":[{"name":"spring","slug":"spring","permalink":"http://yemengying.com/categories/spring/"}],"tags":[{"name":"java","slug":"java","permalink":"http://yemengying.com/tags/java/"},{"name":"spring","slug":"spring","permalink":"http://yemengying.com/tags/spring/"},{"name":"rabbitMq","slug":"rabbitMq","permalink":"http://yemengying.com/tags/rabbitMq/"}]},{"title":"spring事务管理总结","slug":"spring事务管理总结","date":"2015-09-12T06:44:29.000Z","updated":"2016-02-03T07:38:24.000Z","comments":true,"path":"2015/09/12/spring事务管理总结/","link":"","permalink":"http://yemengying.com/2015/09/12/spring事务管理总结/","excerpt":"以前写在segmentFault上的一篇文章 搬移到这里。 在项目开发过程中经常会使用事务来确保数据的一致性。根据网上的资料整理一下在spring中配置事务的几种方式。无论是哪种方式都需要在配置文件中配置连接池和事务管理器,代码如下。","keywords":null,"text":"以前写在segmentFault上的一篇文章 搬移到这里。 在项目开发过程中经常会使用事务来确保数据的一致性。根据网上的资料整理一下在spring中配置事务的几种方式。无论是哪种方式都需要在配置文件中配置连接池和事务管理器,代码如下。 12345678910111213141516171819202122232425 &lt;!-- 读取配置文件 --&gt; &lt;bean class=\"org.springframework.beans.factory.config.PropertyPlaceholderConfigurer\"&gt; &lt;property name=\"locations\"&gt; &lt;list&gt; &lt;value&gt;classpath:database.properties&lt;/value&gt; &lt;value&gt;classpath:service.properties&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;property name=\"fileEncoding\" value=\"UTF-8\" /&gt; &lt;property name=\"ignoreResourceNotFound\" value=\"false\" /&gt;&lt;/bean&gt; &lt;!--连接池 --&gt;&lt;bean id=\"dataSource\" class=\"org.springframework.jdbc.datasource.DriverManagerDataSource\"&gt; &lt;property name=\"driverClassName\" value=\"$&#123;db.driver&#125;\" /&gt; &lt;property name=\"url\" value=\"$&#123;db.url&#125;\" /&gt; &lt;property name=\"username\" value=\"$&#123;db.username&#125;\" /&gt; &lt;property name=\"password\" value=\"$&#123;db.password&#125;\" /&gt;&lt;/bean&gt;&lt;!-- 配置事务管理器 --&gt;&lt;bean id=\"transactionManager\" class=\"org.springframework.jdbc.datasource.DataSourceTransactionManager\"&gt; &lt;property name=\"dataSource\" ref=\"dataSource\" /&gt;&lt;/bean&gt; 声明式事务管理基于AspectJ的XML方式的配置这是我觉得最好的方式，基于aop配置，当新增的方法要使用事务管理时，无需修改代码。首先在配置文件xml中引入aop和tx的命名空间123456xmlns:tx=\"http://www.springframework.org/schema/tx\" xmlns:aop=\"http://www.springframework.org/schema/aop\"xsi:schemaLocation=\"http://www.springframework.org/schema/txhttp://www.springframework.org/schema/tx/spring-tx-3.0.xsdhttp://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-3.0.xsd\" 然后在xml中加入aop的配置,下面的配置就是在services的切入点上应用txAdvice的增强，services的切入点就是ymy.com.service.impl包下的所有方法应用txAdvice的增强。然后txAdvice是在所有以create,add,delete,update,change开头的方法上加上事务管理。 12345678910111213141516171819202122232425262728 &lt;!-- 定义事务通知 （事务的增强）--&gt;&lt;tx:advice id=\"txAdvice\" transaction-manager=\"transactionManager\"&gt; &lt;!-- 定义方法的过滤规则 --&gt; &lt;tx:attributes&gt; &lt;!-- 所有方法都使用事务 --&gt; &lt;!-- propagation:事务传播行为 isolation：事务隔离 read-only:只读 rollback-for:发生哪些异常回滚 no-rollback-for:发生哪些异常不回滚 timeout:过期信息 --&gt; &lt;tx:method name=\"create*\" propagation=\"REQUIRED\"/&gt; &lt;tx:method name=\"add*\" propagation=\"REQUIRED\"/&gt; &lt;tx:method name=\"delete*\" propagation=\"REQUIRED\"/&gt; &lt;tx:method name=\"update*\" propagation=\"REQUIRED\"/&gt; &lt;tx:method name=\"change*\" propagation=\"REQUIRED\"/&gt; &lt;/tx:attributes&gt;&lt;/tx:advice&gt; &lt;!-- 定义AOP配置 配置切面 --&gt;&lt;aop:config&gt; &lt;!-- 定义一个切入点 --&gt; &lt;aop:pointcut expression=\"execution (* ymy.com.service.impl.*.*(..))\" id=\"services\"/&gt; &lt;!-- 对切入点和事务的通知，进行适配 --&gt; &lt;aop:advisor advice-ref=\"txAdvice\" pointcut-ref=\"services\"/&gt;&lt;/aop:config&gt; 采用这种方式配置，当方法是按照事务定义的规则命名时，都会加入事务管理。 基于注解这种方式是我觉得最简单的，第二推荐。要采用注解的方式，需要在配置文件中开启注解事务。 12&lt;!-- 开启注解事务 --&gt;&lt;tx:annotation-driven transaction-manager=\"transactionManager\"/&gt; 在使用时只需在对应的类上添加注解@Transactional即可 12345@Service@Transactionalpublic class TaskService implements ITaskService &#123;&#125; 也可在使用注解时定义事物的传播级别 隔离行为等。。 1@Transactional(propagation=Propagation.REQUIRED) 基于TransactionProxyFactoryBean这种方式配置比较麻烦，需要为每一个需要事务管理的类配置一个代理类，不推荐使用。例如我要对taskService进行事务管理，需要如下配置，用代理类对目标类进行增强。 12345678910111213&lt;!-- 配置service层的代理 --&gt;&lt;bean id = \"taskServiceProxy\" class=\"org.springframework.transaction.interceptor.TransactionProxyFactoryBean\"&gt; &lt;!-- 配置目标对象 --&gt; &lt;property name = \"target\" ref=\"taskService\"&gt;&lt;/property&gt; &lt;!-- 注入事务管理器 --&gt; &lt;property name = \"transactionManager\" ref=\"transactionManager\"&gt;&lt;/property&gt; &lt;!-- 设置需要事务管理的方法 --&gt; &lt;property name=\"transactionAttributes\"&gt; &lt;props&gt; &lt;prop key=\"update*\"&gt;PROPAGATION_REQUIRED&lt;/prop&gt; &lt;/props&gt; &lt;/property&gt;&lt;/bean&gt; 之后在注入service类时，就要注入它的代理类。 12@Resource(name = \"taskServiceProxy\")private ITaskService taskSerivce; 编程式事务管理超级不推荐，需要为每个类注入事务模板，然后在需要事务管理的方法中使用事务模板。 123456789101112private TransactionTemplate transactionTemplate;public void test()&#123; transactionTemplate.execute(new TransactionCallbackWithoutResult() &#123; @Override protected void doInTransactionWithoutResult(TransactionStatus status) &#123; //进行事务相应的操作。。。 //方法一... //方法二... &#125; &#125;); &#125;","raw":null,"content":null,"categories":[{"name":"spring","slug":"spring","permalink":"http://yemengying.com/categories/spring/"}],"tags":[{"name":"java","slug":"java","permalink":"http://yemengying.com/tags/java/"},{"name":"spring","slug":"spring","permalink":"http://yemengying.com/tags/spring/"},{"name":"transaction","slug":"transaction","permalink":"http://yemengying.com/tags/transaction/"},{"name":"spring-aop","slug":"spring-aop","permalink":"http://yemengying.com/tags/spring-aop/"}]},{"title":"使代码更简洁(二)---集合转换相关","slug":"使代码更简洁-二-集合转换相关","date":"2015-09-11T06:34:33.000Z","updated":"2016-04-22T13:43:44.000Z","comments":true,"path":"2015/09/11/使代码更简洁-二-集合转换相关/","link":"","permalink":"http://yemengying.com/2015/09/11/使代码更简洁-二-集合转换相关/","excerpt":"以前在segmentFault上的一篇文章 搬移到这里。 记录一下在工作开发中封装的一些工具类，使代码看起来更加的简洁。这篇就记录下和集合转换相关的吧。。。。。会持续记录。。。。","keywords":null,"text":"以前在segmentFault上的一篇文章 搬移到这里。 记录一下在工作开发中封装的一些工具类，使代码看起来更加的简洁。这篇就记录下和集合转换相关的吧。。。。。会持续记录。。。。 list转map 开发过程中经常会碰到需要将list转为map的情况，例如有一个User类，有id,name,age等属性。有一个User的list，为了很方便的获取指定id的User，这时就需要将List&lt; User&gt;转换为Map，其中map的key是User的id。一般的做法，是通过for循环将list中的元素put到map中，代码如下： 1234Map&lt;Integer, User&gt; map = new HashMap&lt;Integer, User&gt;();for(User user : userList)&#123; map.put(user.getId(), user);&#125; 这样做，在每个需要将list转为map的地方，都要写一遍for循环，代码不够简洁，所以利用stream和泛型封装了一个通用的工具方法 1234567891011121314public class TransFormUtils &#123; /** * 将list转为map * @param list * @param predicate1 key * @param predicate2 value * @return */ public static&lt;K,V,T&gt; Map&lt;K, V&gt; transformToMap(List&lt;T&gt; list,Function&lt;T, K&gt; predicate1, Function&lt;T,V&gt; predicate2)&#123; return list.stream().collect(Collectors.toMap(predicate1, predicate2)); &#125;&#125; 这样如果需要将List&lt; User&gt;转为Map代码如下 12//省略list构造过程Map&lt;Integer, User&gt; map = TransFormUtils.transformToMap(userList, p-&gt;p.getId(), p-&gt;p); 如果需要将List&lt; User&gt;转为Map代码如下 12//省略list构造过程Map&lt;Integer, String&gt; map2 = TransFormUtils.transformToMap(userList, p-&gt;p.getId(), p-&gt;p.getName()); 应用封装好的工具类 只需要一行代码就可以完成list到map的转换，程序简单了许多~~ list&lt; T &gt;转map&lt; K,List&lt; V&gt;&gt;将开发中经常需要根据list中的某个属性将list分类。举个例子，在开发通知中心时需要给用户推送消息，安卓和ios是调用的不同的第三方库，所以要根据设备的类型调用不同的方法。首先根据要推送的用户Id列表获得List&lt; DeviceUser&gt;,DeviceUser类的属性包括devicetype,deviceId,userId,userName,createAt等。接着要获得deviceType是ios的deviceId列表，deviceType是安卓的deviceId列表。即将List&lt; DeviceUser&gt;转为Map&lt; Integer,List&lt; String&gt;&gt;，其中map的key是deviceType，value是deviceId的list。为了解决这个问题，写了一个通用的工具类。 1.利用stream12345678910111213141516public class TransFormUtils &#123; /** * 将list&lt;T&gt;转为Map&lt;K,List&lt;V&gt;&gt; * @param list * @param predicate1 map中的key * @param predicate2 map中的list的元素 * @return */ public static &lt;K,V,T&gt; Map&lt;K, List&lt;V&gt;&gt; transformToMapList(List&lt;T&gt; list, Function&lt;T, K&gt; predicate1, Function&lt;T,V&gt; predicate2)&#123; return list.stream().collect( Collectors.groupingBy(predicate1, Collectors.mapping(predicate2, Collectors.toList()))); &#125;&#125; 使用如下： 123List&lt;DeviceUser&gt; list = new ArrayList&lt;DeviceUser&gt;();//省略list的构造Map&lt;Integer, List&lt;String&gt;&gt; deviceMap = TransFormUtils.transformToMapList(list, p-&gt;p.getDeviceType(), p-&gt;p.getDeviceId()); 2.普通方法同事也写了一个另一个工具类,这种方法定义了一个新的数据结构，直接使用MapList代替Map 123456789101112131415161718192021222324252627282930/** * Map&amp;List组合数据结构 * * @author jianming.zhou * * @param &lt;K&gt; * @param &lt;V&gt; */public class MapList&lt;K, V&gt; &#123; private Map&lt;K, List&lt;V&gt;&gt; map = new HashMap&lt;K, List&lt;V&gt;&gt;(); public List&lt;V&gt; get(K k) &#123; return map.get(k); &#125; public void put(K k, V v) &#123; if (map.containsKey(k)) &#123; map.get(k).add(v); &#125; else &#123; List&lt;V&gt; list = new ArrayList&lt;V&gt;(); list.add(v); map.put(k, list); &#125; &#125; public Set&lt;K&gt; keySet() &#123; return map.keySet(); &#125;&#125; 使用如下123456List&lt;DeviceUser&gt; list = new ArrayList&lt;DeviceUser&gt;();//省略list的构造MapList&lt;Integer, String&gt; deviceMap = new MapList&lt;Integer,String&gt;();for(DeviceUser device : list)&#123; deviceMap.put(device.getDeviceType(),device.getDeviceId());&#125; 还是喜欢第一种哈哈哈哈哈哈~~题外话：既然对现状不满意 就尝试改变吧 虽然有可能进入另一个坑~~","raw":null,"content":null,"categories":[{"name":"java","slug":"java","permalink":"http://yemengying.com/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"http://yemengying.com/tags/java/"},{"name":"stream","slug":"stream","permalink":"http://yemengying.com/tags/stream/"},{"name":"list","slug":"list","permalink":"http://yemengying.com/tags/list/"},{"name":"map","slug":"map","permalink":"http://yemengying.com/tags/map/"}]},{"title":"使代码更简洁(一)---List相关","slug":"使代码更简洁-一-List相关","date":"2015-09-10T06:07:54.000Z","updated":"2016-04-22T13:43:56.000Z","comments":true,"path":"2015/09/10/使代码更简洁-一-List相关/","link":"","permalink":"http://yemengying.com/2015/09/10/使代码更简洁-一-List相关/","excerpt":"以前写在segmentFault上的一篇文章 搬移到这里。 记录一下在工作开发中封装的一些工具类，使代码看起来更加的简洁。这篇就记录下和list相关的吧。。。。。会持续记录。。。。","keywords":null,"text":"以前写在segmentFault上的一篇文章 搬移到这里。 记录一下在工作开发中封装的一些工具类，使代码看起来更加的简洁。这篇就记录下和list相关的吧。。。。。会持续记录。。。。 利用stream代替for循环 在对list的操作中常常需要for循环来遍历整个list，代码看起来不够简洁。所以利用java8的新特性Stream来代替for循环，提高程序的可读性。从网上coyp了一些stream的介绍：Stream 不是集合元素，它不是数据结构并不保存数据，它是有关算法和计算的，它更像一个高级版本的 Iterator。原始版本的 Iterator，用户只能显式地一个一个遍历元素并对其执行某些操作；高级版本的 Stream，用户只要给出需要对其包含的元素执行什么操作，比如 “过滤掉长度大于 10 的字符串”、“获取每个字符串的首字母”等，Stream 会隐式地在内部进行遍历，做出相应的数据转换。Stream 就如同一个迭代器（Iterator），单向，不可往复，数据只能遍历一次，遍历过一次后即用尽了，就好比流水从面前流过，一去不复返。而和迭代器又不同的是，Stream 可以并行化操作，迭代器只能命令式地、串行化操作。顾名思义，当使用串行方式去遍历时，每个 item 读完后再读下一个 item。而使用并行去遍历时，数据会被分成多个段，其中每一个都在不同的线程中处理，然后将结果一起输出。Stream 的并行操作依赖于 Java7 中引入的 Fork/Join 框架（JSR166y）来拆分任务和加速处理过程。下面是一些利用stream写的工具类 打印list中的元素123456789101112131415/** * * @author yemengying * */public class ListUtils &#123; /** * 打印list中的元素 * @param list */ public static &lt;T&gt; void printList(List&lt;T&gt; list)&#123; if(null == list) list = new ArrayList&lt;T&gt;(); list.stream().forEach(n -&gt; System.out.println(n.toString())); &#125;&#125; 从list中删除指定的元素12345678910111213141516171819202122/** * * @author yemengying * */public class ListUtils &#123; /** * 从list中删除指定的元素 其他类需重写equals方法 * @param list * @param arg 要删除的元素 * @return 返回删除了指定元素的list * eg:list:[1,2,3,1]---removeElementFromList(list,1)---return list:[2,3] */ public static &lt;T&gt; List&lt;T&gt; removeElementFromList(List&lt;T&gt; list, T arg)&#123; if(null == list || list.isEmpty()) return new ArrayList&lt;T&gt;(); if(arg == null) return list; return list.stream().filter(n -&gt; &#123; return !n.equals(arg); &#125;).collect(Collectors.toList()); &#125;&#125; list排序12345678910111213141516171819202122232425262728/** * * @author yemengying * */public class ListUtils &#123; /** * list排序 * @param list * @param comparator * @return 返回按comparator排好序的list * eg:User:id name两个属性 * List&lt;User&gt; userList = new ArrayList&lt;User&gt;(); * userList.add(new User(1,\"abc\")); * userList.add(new User(3, \"ccd\")); * userList.add(new User(2, \"bde\")); * 1.按user名字排序 * userList = ListUtils.sortList(userList, (p1, p2) -&gt; p1.getName().compareTo(p2.getName())); * 2.按user Id排序 * userList = ListUtils.sortList(userList, (p1, p2) -&gt; p1.getId()-p2.getId()); */ public static &lt;T&gt; List&lt;T&gt; sortList(List&lt;T&gt; list, Comparator&lt;? super T&gt; comparator)&#123; if(null == list || list.isEmpty()) return new ArrayList&lt;T&gt;(); if(null == comparator) return list; return list.stream().sorted(comparator).collect(Collectors.toList()); &#125;&#125; 判读list中的元素是不是全部满足 指定条件12345678910111213141516171819202122232425/** * * @author yemengying * */public class ListUtils &#123; /** * 判读list中的元素是不是全部满足 predicate的条件 * @param list * @param predicate * @return 全部满足 true 有不满足的 false * eg：判断list中的user的id是不是均小于4 * List&lt;User&gt; userList = new ArrayList&lt;User&gt;(); * userList.add(new User(1,\"abc\")); * userList.add(new User(3, \"ccd\")); * userList.add(new User(2, \"bde\")); * System.out.println(ListUtils.isAllMatch(userList, u -&gt; u.getId()&lt;4)); * 输出 true */ public static &lt;T&gt; boolean isAllMatch(List&lt;T&gt; list, Predicate&lt;? super T&gt; predicate)&#123; if(null == list || list.isEmpty()) return false; if(null == predicate) return false; return list.stream().allMatch(predicate); &#125;&#125; 判断list中是不是有一个元素满足predicate的条件123456789101112131415161718192021222324/** * * @author yemengying * */public class ListUtils &#123; /** * 只要有一个元素满足predicate的条件 返回true * @param list * @param predicate * @return * eg：判断list中的user的id是不是有一个大于4 * List&lt;User&gt; userList = new ArrayList&lt;User&gt;(); * userList.add(new User(1,\"abc\")); * userList.add(new User(3, \"ccd\")); * userList.add(new User(2, \"bde\")); * System.out.println(ListUtils.isAllMatch(userList, u -&gt; u.getId()&gt;4)); return false */ public static &lt;T&gt; boolean isAnyMatch(List&lt;T&gt; list, Predicate&lt;? super T&gt; predicate)&#123; if(null == list || list.isEmpty()) return false; if(null == predicate) return false; return list.stream().anyMatch(predicate); &#125;&#125; 判断list中是不是没有一个元素满足predicate的条件123456789101112131415161718192021222324/** * * @author yemengying * */public class ListUtils &#123; /** * 没有一个元素满足predicate的条件 返回true * @param list * @param predicate * @return * eg：判断list中的user的id是不是有一个大于4 * List&lt;User&gt; userList = new ArrayList&lt;User&gt;(); * userList.add(new User(1,\"abc\")); * userList.add(new User(3, \"ccd\")); * userList.add(new User(2, \"bde\")); * System.out.println(ListUtils.isAllMatch(userList, u -&gt; u.getId()&gt;4)); return true */ public static &lt;T&gt; boolean isNoneMatch(List&lt;T&gt; list, Predicate&lt;? super T&gt; predicate)&#123; if(null == list || list.isEmpty()) return false; if(null == predicate) return false; return list.stream().noneMatch(predicate); &#125;&#125; list去重123456789101112131415161718/** * * @author yemengying * */public class ListUtils &#123; /** * list去重 * @param list * @return * eg: * list[1,2,2]---distinctList(list)---list[1,2] */ public static &lt;T&gt; List&lt;T&gt; distinctList(List&lt;T&gt; list)&#123; if(null == list || list.isEmpty()) return new ArrayList&lt;T&gt;(); return list.stream().distinct().collect(Collectors.toList()); &#125;&#125; 2利用泛型编写一些通用的方法方便的构造一个list在开发时经常遇到要调用一个接口，接口的参数是list。例如在开发通知中心时发送消息的接口定义如下,其中messageForm是要发送的内容，userList是接受者的用户id 1public int pushMessage(MessageForm messageForm,List&lt;Integer&gt; userList); 这样，在给一个人发送消息的时候也需要构造一个list一般的做法,如下: 123List&lt;Integer&gt; list = new ArrayList&lt;Integer&gt;();list.add(8808);pushService.pushMessage(messageForm,list); 比较麻烦，所以同事封装了一个工具方法： 12345678910111213141516171819public class ListUtils &#123; /** * 构造list * @param args * @return * @author zhoujianming */ @SuppressWarnings(\"unchecked\") public static &lt;T&gt; List&lt;T&gt; toList(T...args) &#123; if (null == args) &#123; return new ArrayList&lt;T&gt;(); &#125; List&lt;T&gt; list = new ArrayList&lt;T&gt;(); for (T t : args) &#123; list.add(t); &#125; return list; &#125;&#125; 这样在调用时，比较简洁: 12//给id 8808和8809发消息pushService.pushMessage(messageForm,ListUtils.toList(8808,8809)); 利用递归获得多个list的笛卡尔积获得多个list的笛卡尔积，代码参考stackoverflow 123456789101112131415161718192021222324252627/** * 递归获得多个list的笛卡尔积 * eg[1],[8808],[1,2,3]--&gt;[[1,8808,1],[1,8808,2]] * 参考：http://stackoverflow.com/questions/714108/cartesian-product-of-arbitrary-sets-in-java * @param lists * @return */public static &lt;T&gt; List&lt;List&lt;T&gt;&gt; cartesianProduct(List&lt;List&lt;T&gt;&gt; lists) &#123; List&lt;List&lt;T&gt;&gt; resultLists = new ArrayList&lt;List&lt;T&gt;&gt;(); if (lists.size() == 0) &#123; resultLists.add(new ArrayList&lt;T&gt;()); return resultLists; &#125; else &#123; List&lt;T&gt; firstList = lists.get(0); List&lt;List&lt;T&gt;&gt; remainingLists = cartesianProduct(lists.subList(1, lists.size())); for (T condition : firstList) &#123; for (List&lt;T&gt; remainingList : remainingLists) &#123; ArrayList&lt;T&gt; resultList = new ArrayList&lt;T&gt;(); resultList.add(condition); resultList.addAll(remainingList); resultLists.add(resultList); &#125; &#125; &#125; return resultLists;&#125; 使用时将需要获得笛卡尔积的多个list放到一个list里，调用上面的方法即可，调用示例如下： 12345List&lt;Integer&gt; list1 = Arrays.asList(1,2,3);List&lt;Integer&gt; list2 = Arrays.asList(8808,8809,8810);List&lt;Integer&gt; list3 = Arrays.asList(4);List&lt;List&lt;Integer&gt;&gt; lists = Arrays.asList(list1,list2,list3);List&lt;List&lt;Integer&gt;&gt; resultLists = ListUtils.cartesianProduct(lists); [1,2,3],[8808,8809,8810],[4]——&gt;[[1, 8808, 4], [1, 8809, 4], [1, 8810, 4], [2, 8808, 4], [2, 8809, 4], [2, 8810, 4], [3, 8808, 4], [3, 8809, 4], [3, 8810, 4]]","raw":null,"content":null,"categories":[{"name":"java","slug":"java","permalink":"http://yemengying.com/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"http://yemengying.com/tags/java/"},{"name":"stream","slug":"stream","permalink":"http://yemengying.com/tags/stream/"},{"name":"list","slug":"list","permalink":"http://yemengying.com/tags/list/"}]},{"title":"angularjs+bootstrap+ngDialog实现模式对话框","slug":"angularjs-bootstrap-ngDialog实现模式对话框","date":"2015-09-08T06:07:54.000Z","updated":"2016-04-23T02:08:57.000Z","comments":true,"path":"2015/09/08/angularjs-bootstrap-ngDialog实现模式对话框/","link":"","permalink":"http://yemengying.com/2015/09/08/angularjs-bootstrap-ngDialog实现模式对话框/","excerpt":"在完成一个后台管理系统时，需要用表格显示注册用户的信息。但是用户地址太长了，不好显示。所以想做一个模式对话框，点击详细地址按钮时，弹出对话框，显示地址。","keywords":null,"text":"在完成一个后台管理系统时，需要用表格显示注册用户的信息。但是用户地址太长了，不好显示。所以想做一个模式对话框，点击详细地址按钮时，弹出对话框，显示地址。效果如下图： 通过查阅资料，选择使用ngDialog来实现，ngDialog是一个用于Angular.js应用的模式对话框和弹出窗口。ngDialog非常小（〜2K），拥有简约的API，通过主题高度可定制的，具有唯一的依赖Angular.js。ngDialog github地址: https://github.com/likeastore/ngDialogngDialog Demo : http://likeastore.github.io/ngDialog/首先引入需要的ngdialog的js和css文件。可通过CDN引入 1234//cdnjs.cloudflare.com/ajax/libs/ng-dialog/0.3.7/css/ngDialog.min.css //cdnjs.cloudflare.com/ajax/libs/ng-dialog/0.3.7/css/ngDialog-theme-default.min.css //cdnjs.cloudflare.com/ajax/libs/ng-dialog/0.3.7/css/ngDialog-theme-plain.min.css //cdnjs.cloudflare.com/ajax/libs/ng-dialog/0.3.7/js/ngDialog.min.js 在user.js里的controller中注入依赖 1234567891011121314151617181920var userControllers = angular.module('userControllers',['ngDialog']); userControllers.controller('userController',['$scope','$http','ngDialog',function($scope,$http, ngDialog)&#123; $scope.name = 'user'; $scope.user = \"\"; $scope.address = \"\"; //获取用户信息 $http.get('http://localhost:3000/users').success(function(data) &#123; $scope.user = data; console.log($scope.user); &#125;); //点击详细地址按钮时，跳出模式对话框 $scope.clickToAddress = function (address) &#123; $scope.address = address; ngDialog.open(&#123; template: 'views/test.html',//模式对话框内容为test.html className: 'ngdialog-theme-plain', scope:$scope //将scope传给test.html,以便显示地址详细信息 &#125;); &#125;; &#125;]) test.html(读取scope中的address并显示，表格样式采用bootstrap) 1234567891011121314151617181920212223242526272829&lt;table class=\"table\"&gt; &lt;thead&gt; &lt;tr&gt; &lt;th&gt; 收件人姓名 &lt;/th&gt; &lt;td&gt; &#123;&#123;address.name&#125;&#125; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;th&gt; 收件地址 &lt;/th&gt; &lt;td&gt; &#123;&#123;address.content&#125;&#125; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;th&gt; 手机号 &lt;/th&gt; &lt;td&gt; &#123;&#123;address.phone&#125;&#125; &lt;/td&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;/table&gt; user.html (显示用户的信息，当地址不为空时，显示详细地址按钮，并点击按钮时，调用controller中的clickToAddress函数) 123456789101112131415161718192021222324252627282930313233343536373839404142&lt;div&gt; &lt;div class=\"panel panel-warning\"&gt; &lt;div class=\"panel-heading\"&gt; 用户管理 &lt;/div&gt; &lt;div class=\"row\"&gt; &lt;div class=\"col-lg-8\"&gt;&lt;/div&gt; &lt;div class=\"col-lg-4\"&gt; &lt;div class=\"input-group\"&gt; &lt;input type=\"text\" class=\"form-control\" placeholder=\"Search for...\" ng-model='search'&gt; &lt;span class=\"input-group-btn\"&gt; &lt;button class=\"btn btn-default\" type=\"button\"&gt;Go!&lt;/button&gt; &lt;/span&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;table class=\"table\"&gt; &lt;thead&gt; &lt;th&gt;姓名&lt;/th&gt; &lt;th&gt;余额 &lt;span class=\"glyphicon glyphicon-flash\" aria-hidden=\"true\"&gt; &lt;/span&gt;&lt;/th&gt; &lt;th&gt;头像&lt;/th&gt; &lt;th&gt;默认地址&lt;/th&gt; &lt;th&gt;操作&lt;/th&gt; &lt;/thead&gt; &lt;tbody&gt; &lt;tr ng-repeat=\"user in user | filter : search\" &gt; &lt;td&gt;&#123;&#123;user.userName&#125;&#125;&lt;/td&gt; &lt;td&gt;&#123;&#123;user.residualPayment&#125;&#125;&lt;/td&gt; &lt;td ng-if=\"user.url != 'undefined' \"&gt;&#123;&#123;user.url&#125;&#125;&lt;/td&gt; &lt;td ng-if=\"user.url == 'undefined' \"&gt;系统默认头像&lt;/td&gt; &lt;td ng-if=\"user.address.length == 0 \"&gt;暂无默认地址&lt;/td&gt; &lt;td ng-if=\"user.address.length != 0\"ng-repeat=\"address in user.address \" ng-click=\"clickToAddress(address)\"&gt; &lt;button type=\"button\" class=\"btn btn-info navbar-btn\"&gt;详细地址&lt;/button&gt; &lt;/td&gt; &lt;td&gt; &lt;button type=\"button\" class=\"btn btn-warning navbar-btn\" ng-click=\"remove(user._id)\"&gt;删除&lt;/button&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;/div&gt; &lt;/div&gt; git地址: loadStyle(\"/hexo-github/style.css\"); loadStyle(\"/hexo-github/octicons/octicons.css\"); new Badge(\"#badge-container-giraffe0813-hellofreshAdmin-278d259\", \"giraffe0813\", \"hellofreshAdmin\", \"278d259\", false);","raw":null,"content":null,"categories":[{"name":"angularJs","slug":"angularJs","permalink":"http://yemengying.com/categories/angularJs/"}],"tags":[{"name":"angularJs","slug":"angularJs","permalink":"http://yemengying.com/tags/angularJs/"},{"name":"ngDialog","slug":"ngDialog","permalink":"http://yemengying.com/tags/ngDialog/"},{"name":"bootstrap","slug":"bootstrap","permalink":"http://yemengying.com/tags/bootstrap/"}]}]}